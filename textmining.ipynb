{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining - Document Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History:\n",
    "\n",
    "- 2017/9/7: \n",
    "    - 移除文章內的google廣告語法\n",
    "    - 用逗號和問號斷句\n",
    "    - 加入similar words\n",
    "        - check read01_summary\n",
    "    - 加入兩張圖(tf-idf keywords, similar words)\n",
    "        - check keywordmap\n",
    "- 2017/9/11:\n",
    "    - 建立user dict\n",
    "    - 用jieba抓tfidf key words\n",
    "- 2017/9/12:\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- 用scikit-learn学习LDA主题模型\n",
    "    - http://www.cnblogs.com/pinard/p/6908150.html\n",
    "    - http://blog.csdn.net/eastmount/article/details/50824215\n",
    "    \n",
    "- 中文文本挖掘预处理流程总结\n",
    "    - http://www.cnblogs.com/pinard/p/6744056.html\n",
    "    \n",
    "- Mining English and Korean text with Python\n",
    "    https://www.lucypark.kr/courses/2015-ba/text-mining.html\n",
    "    \n",
    "- NLTK (POS, chunk, Parser tree)    \n",
    "    - http://aweiho2015.pixnet.net/blog/post/10269587-%5B%E8%AA%8D%E8%AD%98%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%28text-mining%29%5D--%E5%A6%82%E4%BD%95%E8%99%95%E7%90%86%E4%B8%80%E5%8F%A5\n",
    "    \n",
    "- TF-IDF and TextRank\n",
    "    - http://zhicongchen.github.io/2016/11/22/TF-IDF-and-TextRank/\n",
    "    \n",
    "- 中文斷詞：斷句不要悲劇 / Head first Chinese text segmentation    \n",
    "    - https://speakerdeck.com/fukuball/head-first-chinese-text-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "-  [斷詞 (Jieba)]()\n",
    "-  [計算高頻詞 (TF-IDF)]()\n",
    "-  [Key words and key sentence summary]()\n",
    "-  [Word Embedding (word2vec)]()  \n",
    "-  [降維 (T-SNE)]()\n",
    "-  [key word map]()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO **\n",
    "\n",
    "9/2: \n",
    "1. Ontology, 搜尋, 分類\n",
    "2. 每首歌的屬性, Josh做的5大象限\n",
    "3. 每首歌的知識圖譜?\n",
    "    - http://bangqu.com/J8z3Dx.html \n",
    "    \n",
    "4. Summary:\n",
    "    - v1. 取每首歌的前3個關鍵字, 用包含這三個關鍵字的句子當做summary\n",
    "    - v3. 用每首歌的前3個關鍵字當作3個topic, 找到包含這三個關鍵字的句子與其相似的句子做出三段summary\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import langconv as langconv\n",
    "conveter = langconv.Converter('zh-hant')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import random\n",
    "from flask import Flask, g, render_template, request\n",
    "import logging\n",
    "import html_template as ht\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "punct = u'''\\n +-％%:!),.:;?]}¢'\"、。〉》」』】〕〗〞︰︱︳丨﹐､﹒﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠々‖•·ˇˉ―′’”([{£¥'\"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻︽︿﹁﹃﹙﹛﹝（｛“‘—_…~/#><'''\n",
    "jieba.set_dictionary('dict.txt.big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = matplotlib.font_manager.FontProperties(fname = 'font/NotoSansCJKtc-Regular.otf')\n",
    "matplotlib.font_manager.fontManager.ttffiles.append(fp.get_file())\n",
    "font_entry = matplotlib.font_manager.FontEntry(fp.get_file(), name=fp.get_name(),\n",
    "                                               style=fp.get_style(), variant=fp.get_variant(),\n",
    "                                              weight=fp.get_weight(), stretch=fp.get_stretch(), size=fp.get_size())\n",
    "\n",
    "matplotlib.font_manager.fontManager.ttflist.append(font_entry)\n",
    "plt.rcParams['font.family'] = fp.get_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 斷詞, CountVectorizer, TfidfTransformer, Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 一篇文章分析 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/jayhsu/work/github/textmining/dict.txt.big ...\n",
      "Loading model from cache /var/folders/yf/hq7ghg4j3ksb8k34wyh8vk2m0000gn/T/jieba.ub36e993abda9bbf53d1f5b38e3ae9b44.cache\n",
      "Loading model cost 2.452 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keywords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a74e4e52c99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdl_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_voc_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_vockey_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_w2v_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread01_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text/techdoc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'深度學習'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkw_topn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-221d5f23e89f>\u001b[0m in \u001b[0;36mread01_summary\u001b[0;34m(folder, topic, kw_topn)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvecs2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mdl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_dic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkw_topn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mdl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keywords' is not defined"
     ]
    }
   ],
   "source": [
    "dl_df, dl_voc_dic, dl_vockey_dic, dl_w2v_model, dl_pca = read01_summary(folder = 'text/techdoc', topic='深度學習',kw_topn=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. 檢查斷詞效果 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "斷詞:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dl_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d5993955159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdocid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'斷詞:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dl_df' is not defined"
     ]
    }
   ],
   "source": [
    "docid=13\n",
    "print('斷詞:')\n",
    "print(', '.join(list(dl_df['words'][docid])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 把需要修正的詞加入自訂義字典 \n",
    " - 紀錄load_userdict後仍然斷錯的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. extract key words **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - TF-IDF (IDF: 100篇read01的深度學習文章)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('keywords:')\n",
    "#print(', '.join(list(v['keywords'][docid])))\n",
    "kw_x, kw_y = zip(*(dl_df['keywords_w'][docid][:40]))\n",
    "kw_y = list(map(lambda x: float('%.3f'% x),kw_y))\n",
    "\n",
    "\n",
    "tfvec=dl_df['tf_vector'][docid]\n",
    "tfidf_df = pd.DataFrame({'keyword':kw_x, 'tfidf':kw_y})\n",
    "tfidf_df['tf']=tfidf_df['keyword'].map(lambda x: tfvec[dl_vockey_dic[x]])\n",
    "display(tfidf_df[:6])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(kw_y)), kw_y, label='tfidf')\n",
    "plt.bar(range(len(kw_y)), tfidf_df['tf'], label='tf')\n",
    "plt.xticks(range(len(kw_x)), kw_x,rotation=60, fontsize=12)\n",
    "plt.legend()\n",
    "plt.title('tfidf keywords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - TF-IDF (IDF: jieba內建語料庫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('keywords_jb:')\n",
    "kw_x, kw_y = zip(*(dl_df['keywords_jb'][docid][:40]))\n",
    "kw_y = list(map(lambda x: float('%.3f'% x),kw_y))\n",
    "\n",
    "tfvec=dl_df['tf_vector'][docid]\n",
    "tfidf_df = pd.DataFrame({'keyword':kw_x, 'tfidf':kw_y})\n",
    "tfidf_df['tf']=tfidf_df['keyword'].map(lambda x: tfvec[dl_vockey_dic[x.lower()]])\n",
    "display(tfidf_df[:6])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(kw_y)), kw_y, label='tfidf')\n",
    "plt.bar(range(len(kw_y)), tfidf_df['tf'], label='tf')\n",
    "plt.xticks(range(len(kw_x)), kw_x,rotation=60, fontsize=12)\n",
    "plt.legend()\n",
    "plt.title('tfidf keywords')\n",
    "plt.ylim(0,0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Topic **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - word2vec word similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keywords_predefined = ['NVIDIA', '黃仁勛', 'GPU', '深度學習']\n",
    "\n",
    "kw_x = jieba.analyse.tfidf(dl_df['doc'][docid],topK=100, withWeight=False)\n",
    "#kw_x = jieba.analyse.textrank(dl_df['doc'][docid],topK=100, withWeight=False)\n",
    "vec_kw = [list(dl_w2v_model[w.lower()]) for w in kw_x]\n",
    "\n",
    "vec_pca = dl_pca.transform(vec_kw)\n",
    "tsne = TSNE(perplexity=10, n_components=2, init='pca', n_iter=10000,)\n",
    "vec_tsne = tsne.fit_transform(vec_pca)\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.scatter(vec_pca[:, 0], vec_pca[:, 1], s= 20, label='top 100 words')\n",
    "for i, label in enumerate(kw_x):\n",
    "    x, y = vec_pca[i][:2]\n",
    "    if label in keywords_predefined:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color='black'\n",
    "    plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=13,\n",
    "                 color=color,\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "for i1, label_1 in enumerate(kw_x):\n",
    "    x1, y1 = vec_pca[i1][:2]\n",
    "    for i2, label_2 in enumerate(kw_x):\n",
    "        x2, y2 = vec_pca[i2][:2]\n",
    "        similarity = dl_w2v_model.similarity(label_1.lower(), label_2.lower())\n",
    "        if(similarity>0.7):\n",
    "            plt.plot([x1,x2], [y1,y2])\n",
    "plt.title('pca')\n",
    "    \n",
    "    \n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.scatter(vec_tsne[:, 0], vec_tsne[:, 1], s= 20, label='top 100 words')\n",
    "for i, label in enumerate(kw_x):\n",
    "    x, y = vec_tsne[i][:2]\n",
    "    if label in keywords_predefined:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color='black'\n",
    "    plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=13,\n",
    "                 color=color,\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "\n",
    "for i1, label_1 in enumerate(kw_x):\n",
    "    x1, y1 = vec_tsne[i1][:2]\n",
    "    for i2, label_2 in enumerate(kw_x):\n",
    "        x2, y2 = vec_tsne[i2][:2]\n",
    "        similarity = dl_w2v_model.similarity(label_1.lower(), label_2.lower())\n",
    "        if(similarity>0.6):\n",
    "            plt.plot([x1,x2], [y1,y2])\n",
    "plt.title('pca+tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_num = 5\n",
    "doc = dl_df['doc_tmp'][13]\n",
    "paragraph = doc.split('\\n')\n",
    "\n",
    "paragraph_cutstrlist=[]\n",
    "for p in paragraph:\n",
    "    if p =='...':\n",
    "        continue\n",
    "    p_cut = jieba.cut(p)\n",
    "    p_cut_str = ' '.join(p_cut)\n",
    "    paragraph_cutstrlist.append(p_cut_str)\n",
    "    \n",
    "#从文件导入停用词表\n",
    "stpwrdpath = \"model/stop_words.txt\"\n",
    "stpwrd_dic = open(stpwrdpath, 'r')\n",
    "stpwrd_content = stpwrd_dic.read()\n",
    "#将停用词表转换为list  \n",
    "stpwrdlst = stpwrd_content.splitlines()\n",
    "stpwrd_dic.close()\n",
    "\n",
    "cntVector = CountVectorizer(stop_words=stpwrdlst)\n",
    "cntTf = cntVector.fit_transform(paragraph_cutstrlist)\n",
    "fea = cntVector.get_feature_names()\n",
    "lda = LatentDirichletAllocation(n_topics=topic_num,\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "docres = lda.fit_transform(cntTf)\n",
    "\n",
    "topiclist = np.argmax(docres, axis=1)\n",
    "doc_topic = pd.DataFrame({ 'sentence:':paragraph_cutstrlist,'topic':topiclist})\n",
    "display(doc_topic.sort_values(by='topic'))\n",
    "\n",
    "\n",
    "lda_kwlist= []\n",
    "for i in lda.components_:\n",
    "    kw, weight = sort2list(i, fea)\n",
    "    lda_kwlist.append(zip(kw,weight))\n",
    "topic_kw = pd.DataFrame(lda_kwlist)\n",
    "display(topic_kw.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ontology / Knowledge map **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key words:\n",
    "1. 把文章印出來\n",
    "2. 標出關鍵字\n",
    "3. Jieba斷字有沒有錯誤？ -> 建立斷詞字典-positive\n",
    "4. 關鍵字裡面有沒有需要加入stop words的字？ -> 建立斷詞字典-negagive\n",
    "5. AI找到的關鍵字和HI找到的差異比對, \n",
    "  - AI漏掉的, 為什麼漏掉？\n",
    "  - HI漏掉的, 為什麼漏掉？\n",
    "  \n",
    "6. 利用關鍵字建立第一版Ontology分類架構  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar Words:\n",
    "   - 已知的關聯：分類架構\n",
    "   - 位置的關聯：？？？\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort2list(list1, list2):\n",
    "    list1, list2 = (list(t) for t in zip(*sorted(zip(list1, list2),reverse=True)))\n",
    "    return list1, list2\n",
    "\n",
    "def keywords(row, voc_dic, kwtopn=3, withWeight=False):\n",
    "    keywork_list=[]\n",
    "    keyworkWweight_list=[]\n",
    "    tfidf_vec = row['tfidf_vector']\n",
    "    topn = list(set(tfidf_vec))\n",
    "    topn.sort(reverse=True)\n",
    "    for top in topn[:kwtopn]:\n",
    "        if top==0:\n",
    "            continue\n",
    "        winner = np.argwhere([x ==top for x in tfidf_vec ])\n",
    "        idxlist =winner.flatten().tolist() \n",
    "        for i in idxlist:\n",
    "            keywork_list.append(voc_dic.get(i))\n",
    "            keyworkWweight_list.append((voc_dic.get(i), top)  )\n",
    "        if len(keywork_list)>=kwtopn:\n",
    "            break\n",
    "    if withWeight:\n",
    "        return tuple(keyworkWweight_list) \n",
    "    else:\n",
    "        return tuple(keywork_list) \n",
    "    \n",
    "\n",
    "\n",
    "def docsummary(row):\n",
    "    doc_list = row['sentences']\n",
    "    keywords = row['keywords']\n",
    "    if keywords:\n",
    "        keysentencelist=[]\n",
    "        for doc in doc_list:\n",
    "            doc = doc.lower()\n",
    "            for kw in keywords:\n",
    "                if kw in doc and doc not in keysentencelist:\n",
    "                    keysentencelist.append(doc)\n",
    "                    \n",
    "        #summary_str = ','.join(keysentencelist)\n",
    "        summary_str=''\n",
    "        strlen = 0\n",
    "        for sen in keysentencelist[:10]:\n",
    "            if strlen>50:\n",
    "                strlen = len(sen)\n",
    "                summary_str=summary_str+',\\n'+sen\n",
    "            else:\n",
    "                strlen = strlen + len(sen)\n",
    "                summary_str=summary_str+','+sen\n",
    "    else:\n",
    "        summary_str='NA'\n",
    "        \n",
    "    return summary_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 歌詞 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#who_list = ['easonchen','jaychou', 'karenmok','831','mayday']\n",
    "who_list=[w for w in os.listdir('text_dl') if not w.startswith('.')]\n",
    "update=True\n",
    "if update:\n",
    "    jieba.set_dictionary('dict.txt.big')\n",
    "    for who in who_list:\n",
    "        skipwords=()\n",
    "        df = lyrics_summary('text_dl', who, skipwords=skipwords)\n",
    "        #lyrics_df.to_csv('static/data/lyrics_{w}.csv'.format(w=who))\n",
    "        #fh = open('static/data/lyrics_{w}.pkl'.format(w=who), 'wb')\n",
    "        #pickle.dump(lyrics_df, fh)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Text in a specific topic **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl_df['idf_vector'] = dl_df['tfidf_vector']/dl_df['tf_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exlist=['adsbygoogle','...']\n",
    "def read01_summary(folder, topic, kw_topn=3):\n",
    "    files = os.listdir('{f}/{w}'.format(f=folder, w=topic))\n",
    "    docs=[]\n",
    "    fileName=[]\n",
    "    \n",
    "    for fidx, fname in enumerate(files):\n",
    "        if fname.startswith('.') or fname.endswith('.flag') :\n",
    "            continue\n",
    "\n",
    "        file = open('{fd}/{w}/{f}'.format(fd=folder, w=topic, f=fname), 'r') \n",
    "        doc =[] \n",
    "        for line in file.readlines():                          \n",
    "            line = line.strip()\n",
    "            if not len(line):                               \n",
    "                continue                                    \n",
    "            doc.append(line) \n",
    "        if len(doc)==0:\n",
    "            continue\n",
    "        docs.append('\\n'.join(doc))\n",
    "        fileName.append(str(fidx)+'_'+fname)\n",
    "\n",
    "    dl_df = pd.DataFrame({'fname':fileName, 'doc_tmp':docs})\n",
    "    dl_df.sort_values(by='fname')\n",
    "    dl_df['sentences']=dl_df['doc_tmp'].map(lambda x: re.split(\"[\\n\\r，。？]+\", x))\n",
    "    dl_df['sentences']=dl_df['sentences'].map(lambda x: [s for s in x if not any(w in s for w in exlist)])    \n",
    "    dl_df['doc']=dl_df['sentences'].map(lambda x: '\\n'.join(x))\n",
    "    dl_df['words'] =   dl_df['doc'].map(lambda x: [_.lower() for _ in jieba.cut(x) if _ not in punct]) \n",
    "    dl_df['words_str'] = dl_df['words'].map(lambda x: ' '.join(x))\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    vecs1 = cv.fit_transform(dl_df['words_str']).toarray()\n",
    "    \n",
    "    doclen= list(dl_df['words'].map(lambda x:len(x)))\n",
    "    tf_vec = [(a/b).tolist() for a,b in zip(vecs1.tolist(), doclen)]\n",
    "    dl_df['tf_vector'] = tf_vec\n",
    "    fea = cv.get_feature_names()\n",
    "    key = range(len(fea))\n",
    "    voc_dic = dict(zip(key, fea))\n",
    "    vockey_dic = dict(zip(fea, key))\n",
    "    tfidf = TfidfTransformer()\n",
    "    vecs2 = tfidf.fit_transform(vecs1).toarray()\n",
    "    dl_df['tfidf_vector'] = [_ for _ in vecs2]\n",
    "    \n",
    "    dl_df['keywords'] = dl_df.apply(keywords, axis=1, args=(voc_dic,kw_topn,False))\n",
    "    dl_df['keywords'] = dl_df['keywords'].map(list)\n",
    "    \n",
    "    dl_df['keywords_w'] = dl_df.apply(keywords, axis=1, args=(voc_dic,kw_topn,True))\n",
    "    \n",
    "    dl_df['keywords_jb'] = dl_df['doc'].map(lambda x: jieba.analyse.tfidf(x,topK=kw_topn, withWeight=True))\n",
    "    dl_df['keywords_jb'] = dl_df['keywords_jb'].map(list)\n",
    "    \n",
    "    dl_df['keywords_jb'] = dl_df['doc'].map(lambda x: jieba.analyse.extract_tags(x,topK=kw_topn, withWeight=True))\n",
    "    dl_df['keywords_jb'] = dl_df['keywords_jb'].map(list)\n",
    "    \n",
    "    dl_df['summary'] = dl_df.apply(docsummary, axis=1)\n",
    "    \n",
    "    dl_w2v_model = Word2Vec(dl_df['words'], min_count=1, size=100,iter=50)\n",
    "    \n",
    "    #dl_df['similarwords'] =  dl_df['keywords'].map(lambda x: [dl_w2v_model.most_similar(kw , topn=5) for kw in x])\n",
    "    \n",
    "    all_keywords = sum(list(dl_df['keywords']),[])\n",
    "    vec = np.array([dl_w2v_model[w] for w in all_keywords if w in dl_w2v_model ])\n",
    "    dl_pca = PCA(20)\n",
    "    dl_pca.fit(vec)\n",
    "    \n",
    "    return dl_df, voc_dic,vockey_dic, dl_w2v_model, dl_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyrics_summary(folder, topic, skipwords=('作詞','作曲','編曲','監製')):\n",
    "    files = os.listdir('{f}/{w}'.format(f=folder, w=topic))\n",
    "    docs=[]\n",
    "    fileName=[]\n",
    "    pattern = re.compile(\"\\[\\d+\\:\\d+\\.\\d+\\]\")\n",
    "    \n",
    "    for fidx, fname in enumerate(files):\n",
    "        if fname.startswith('.') or fname.endswith('.flag') :\n",
    "            continue\n",
    "\n",
    "        file = open('{fd}/{w}/{f}'.format(fd=folder, w=topic, f=fname), 'r') \n",
    "        doc =[] \n",
    "        for line in file.readlines():                          \n",
    "            line = line.strip()\n",
    "            hastimeflag=pattern.match(line)\n",
    "            hasskipwords = line.startswith(skipwords)\n",
    "            if hastimeflag or hasskipwords:\n",
    "                continue\n",
    "            if not len(line):                               \n",
    "                continue                                    \n",
    "            doc.append(line) \n",
    "        if len(doc)==0:\n",
    "            continue\n",
    "        docs.append('\\n'.join(doc))\n",
    "        fileName.append(str(fidx)+fname)\n",
    "\n",
    "    lyrics_df = pd.DataFrame({'fname':fileName, 'doc':docs})\n",
    "    lyrics_df['sentences']=lyrics_df['doc'].map(lambda x: re.split(\"[\\n\\r，。？]+\", x))\n",
    "    lyrics_df['words'] =   lyrics_df['doc'].map(lambda x: [_.lower() for _ in jieba.cut(x) if _ not in punct]) \n",
    "    lyrics_df['words_str'] = lyrics_df['words'].map(lambda x: ' '.join(x))\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    vecs1 = cv.fit_transform(lyrics_df['words_str']).toarray()\n",
    "    fea = cv.get_feature_names()\n",
    "    key = range(len(fea))\n",
    "    voc_dic = dict(zip(key, fea))\n",
    "    tfidf = TfidfTransformer()\n",
    "    vecs2 = tfidf.fit_transform(vecs1).toarray()\n",
    "    lyrics_df['tfidf_vector'] = [_ for _ in vecs2]\n",
    "\n",
    "    lyrics_df['keywords'] = lyrics_df.apply(keywords, axis=1, args=(voc_dic,))\n",
    "    lyrics_df['keywords'] = lyrics_df['keywords'].map(list)\n",
    "    lyrics_df['summary'] = lyrics_df.apply(docsummary, axis=1)\n",
    "    \n",
    "    dl_w2v_model = Word2Vec(lyrics_df['words'], min_count=1, size=100,iter=20)\n",
    "    lyrics_df['similarwords'] =  lyrics_df['keywords'].map(lambda x: [dl_w2v_model.most_similar(kw , topn=5) for kw in x])\n",
    "    all_keywords = sum(list(lyrics_df['keywords']),[])\n",
    "    vec = np.array([dl_w2v_model[w] for w in all_keywords if w in dl_w2v_model ])\n",
    "    dl_pca = PCA(20)\n",
    "    dl_pca.fit(vec)\n",
    "    return lyrics_df, voc_dic, dl_w2v_model, dl_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mark 會議記錄 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mark_summary():\n",
    "    mark_df = pd.read_csv('text/mark_srt/extract_mark_srt.csv',encoding='utf-16', index_col=False)\n",
    "    docs = mark_df['others'].unique()\n",
    "    tmp=[]\n",
    "    for doc in docs:\n",
    "        if doc =='=====':\n",
    "            continue\n",
    "        sentences = mark_df[mark_df['others']==doc]['mark']\n",
    "        sentences = sentences.dropna()\n",
    "        sentences = list(sentences)\n",
    "        tmp.append( (doc,sentences))\n",
    "    mark_df = pd.DataFrame(tmp, columns = ['fname','sentences'])\n",
    "    mark_df = pd.DataFrame(tmp, columns = ['fname','sentences'])\n",
    "    mark_df['doc'] = mark_df['sentences'].map(lambda x: '\\n'.join(x))\n",
    "    mark_df['words'] =   mark_df['doc'].map(lambda x: [_.lower() for _ in jieba.cut(x) if _ not in punct]) \n",
    "    mark_df['words_str'] = mark_df['words'].map(lambda x: ' '.join(x))\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    vecs1 = cv.fit_transform(mark_df['words_str']).toarray()\n",
    "    fea = cv.get_feature_names()\n",
    "    key = range(len(fea))\n",
    "    voc_dic = dict(zip(key, fea))\n",
    "    #len(voc_dic)\n",
    "    tfidf = TfidfTransformer()\n",
    "    vecs2 = tfidf.fit_transform(vecs1).toarray()\n",
    "    mark_df['tfidf_vector'] = [_ for _ in vecs2]\n",
    "\n",
    "    mark_df['keywords'] = mark_df.apply(keywords, axis=1,args=(voc_dic,))\n",
    "    mark_df['keywords'] = mark_df['keywords'].map(list)\n",
    "    mark_df['summary'] = mark_df.apply(docsummary, axis=1)\n",
    "    \n",
    "    dl_w2v_model = Word2Vec(mark_df['words'], min_count=1, size=100,iter=20)\n",
    "    mark_df['similarwords'] =  mark_df['keywords'].map(lambda x: [dl_w2v_model.most_similar(kw , topn=5) for kw in x])\n",
    "    all_keywords = sum(list(mark_df['keywords']),[])\n",
    "    vec = np.array([dl_w2v_model[w] for w in all_keywords if w in dl_w2v_model ])\n",
    "    dl_pca = PCA(20)\n",
    "    dl_pca.fit(vec)\n",
    "    \n",
    "    return mark_df, voc_dic, dl_w2v_model, dl_pca\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywordmap(lyrics_df, idx, w2v_model,pca,voc_dic, kw_size=30):\n",
    "    figures=[]\n",
    "    all_keywords = sum(list(lyrics_df['keywords']),[])\n",
    "    counter = collections.Counter(all_keywords)\n",
    "    if len(set(all_keywords)) <100:\n",
    "        samples = len(set(all_keywords))\n",
    "    else:\n",
    "        samples = 100\n",
    "    topn_keywords = [w[0] for w in counter.most_common(samples)]\n",
    "    this_keyword = lyrics_df['keywords'][idx]\n",
    "\n",
    "    vec = np.array([w2v_model[w] for w in (topn_keywords+this_keyword)])\n",
    "\n",
    "    vec_pca = pca.transform(vec)\n",
    "    topn_pca = vec_pca[:samples]\n",
    "    this_pca = vec_pca[samples:]\n",
    "\n",
    "    tsne = TSNE(perplexity=10, n_components=2, init='pca', n_iter=10000)\n",
    "    lowdim_embs = tsne.fit_transform(vec_pca)\n",
    "\n",
    "    topn_lowdim_embs = lowdim_embs[:samples]\n",
    "    this_lowdim_embs = lowdim_embs[samples:]\n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    figures.append(fig)\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(topn_lowdim_embs[:, 0], topn_lowdim_embs[:, 1], s= 20, label='top 100 words')\n",
    "    plt.scatter(this_lowdim_embs[:, 0], this_lowdim_embs[:, 1], s= 50, label='this topic key words', color='orange')\n",
    "    plt.legend()\n",
    "    plt.title('PCA + T-SNE')\n",
    "    for i, label in enumerate(topn_keywords):\n",
    "        if label in this_keyword:\n",
    "            continue\n",
    "        x, y = topn_lowdim_embs[i][:2]\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     fontsize=12,\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    for i, label in enumerate(this_keyword):\n",
    "        x, y = this_lowdim_embs[i][:2]\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     fontsize=14,\n",
    "                     ha='right',\n",
    "                     va='bottom',color='orange')\n",
    "    \n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(topn_pca[:, 0], topn_pca[:, 1], s= 20, label='top 100 words')\n",
    "    plt.scatter(this_pca[:, 0], this_pca[:, 1], s= 50, label='this topic key words', color='orange')\n",
    "    plt.legend()\n",
    "    plt.title('PCA')\n",
    "    for i, label in enumerate(topn_keywords):\n",
    "        if label in this_keyword:\n",
    "            continue\n",
    "        x, y = topn_pca[i][:2]\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     fontsize=12,\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    for i, label in enumerate(this_keyword):\n",
    "        x, y = this_pca[i][:2]\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     fontsize=14,\n",
    "                     ha='right',\n",
    "                     va='bottom',color='orange')\n",
    "\n",
    "\n",
    "    fig2 = plt.figure(figsize=(15,6))\n",
    "    figures.append(fig2)\n",
    "    tfidf_vec = lyrics_df['tfidf_vector'][idx]\n",
    "    topn_vec , topn_word= sort2list(list(tfidf_vec) , list(voc_dic.values()))\n",
    "    plt.bar(range(len(topn_vec[:kw_size])), topn_vec[:kw_size])\n",
    "    plt.xticks(range(len(topn_vec[:kw_size])), topn_word[:kw_size],rotation=60, fontsize=12)\n",
    "    plt.title('tfidf keywords')\n",
    "    #print(topn_word[:n])\n",
    "    #plt.show()\n",
    "    \n",
    "    for kw in lyrics_df['keywords'][idx]:\n",
    "        fig3 = plt.figure(figsize=(15,6))\n",
    "        figures.append(fig3)\n",
    "        similarwords = w2v_model.most_similar(kw, topn=kw_size)\n",
    "        words, similarity = zip(*similarwords)\n",
    "        barlist = plt.bar(range(len(similarity)), similarity)\n",
    "        plt.xticks(range(len(similarity)), words,rotation=60, fontsize=12)\n",
    "        plt.title('similar word of {kw}'.format(kw=kw))\n",
    "        #barlist[0].set_color('r')\n",
    "        #print(words)\n",
    "        #plt.show()\n",
    "    return figures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "** flask web **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'text_dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9cabc1c55179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtopic_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_dl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdl_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'text_dl'"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    ['', '', '/', '']\n",
    "    , ['deeplearningSummary', 'docid,topic', '/deeplearningSummary/0/4', 'test']\n",
    "    , ['lyricsSummary', 'lyricid,who', '/lyricsSummary/0/0', 'test']\n",
    "    , ['meetingSummary', 'meetingid', '/meetingSummary/0', 'test']\n",
    "]\n",
    "df_url = pd.DataFrame(urls, columns=['page', 'ps', 'instance', 'remark']).set_index('page')\n",
    "df_url['instance'] = df_url['instance'].map(lambda x: '<a href=\"%s\">%s</a>'%(x, x) if x != '' else '')\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_ps(page, path):\n",
    "    names = df_url.ix[page]['ps'].split(',')\n",
    "    try:\n",
    "        ps = {k: v for k, v in zip(names, path.split('/'))}\n",
    "    except:\n",
    "        ps = {}\n",
    "    return ps\n",
    "\n",
    "def get_route(df_url, page):\n",
    "    return '/%s'%page + ''.join(['/<%s>'%_ for _ in df_url.ix[page]['ps'].split(',') if len(_)>0 ])\n",
    "\n",
    "@app.route('/')\n",
    "def root(**ps):    \n",
    "    cards = [['URL', [['table', df_url.reset_index()[['page', 'instance', 'ps', 'remark']]]] ]]\n",
    "    try:\n",
    "        texts = ['hi, %s'%flask_login.current_user.id]\n",
    "    except:\n",
    "        texts = []\n",
    "    return ht.HtmlTemplate('Root', cards=cards, texts=texts).to_html()\n",
    "\n",
    "\n",
    "topic_list=[w for w in os.listdir('text_dl') if not w.startswith('.')]\n",
    "topic=-1\n",
    "dl_df=None\n",
    "dl_w2v_model=None\n",
    "dl_pca=None\n",
    "dl_voc_dic=None\n",
    "@app.route('/deeplearningSummary/<path:path>')\n",
    "def deeplearningSummary(path=''):\n",
    "    global topic\n",
    "    global dl_df\n",
    "    global dl_w2v_model\n",
    "    global dl_pca\n",
    "    global dl_voc_dic\n",
    "    #print(path)\n",
    "    ps={}\n",
    "    ps = get_ps('deeplearningSummary', path)\n",
    "    #print(ps)\n",
    "    docid = int(ps.get('docid'))  #docid\n",
    "    topic_new = int(ps.get('topic'))  #topic\n",
    "    print(topic_new)\n",
    "    topic_str = topic_list[topic_new]\n",
    "    \n",
    "    if topic!=topic_new:\n",
    "        dl_df, dl_voc_dic, dl_w2v_model, dl_pca = read01_summary(folder = 'text/techdoc', topic=topic_str, kw_topn=50)\n",
    "        tipic=topic_new\n",
    "    \n",
    "    selected_doc = dl_df.ix[docid]\n",
    "    \n",
    "    cards = []\n",
    "    content=[]\n",
    "    \n",
    "    display_detailcols=['fname', 'doc', 'keywords', 'summary']\n",
    "    for col in display_detailcols:\n",
    "        content.append(['text', '<font color=\"blue\">{col}</font>'.format(col=col)])\n",
    "        content.append(['text',selected_doc[col]])\n",
    "    \n",
    "    similarwords=OrderedDict()\n",
    "    for kw in list(dl_df['keywords'][0]):\n",
    "        similarword=dl_w2v_model.most_similar(kw,topn=20)\n",
    "        similarwords[kw]=similarword\n",
    "    similarwords_df = pd.DataFrame(similarwords)\n",
    "    content.append(['text', '<font color=\"blue\">{col}</font>'.format(col='similar words')])\n",
    "    content.append(['table',similarwords_df])\n",
    "    \n",
    "    content.append(['text', '<font color=\"blue\"> Text Summary</font>'])\n",
    "    content.append(['table', dl_df[['fname','keywords','summary']]])\n",
    "    \n",
    "    cards.append(['text summary', content ])\n",
    "    \n",
    "    figs = keywordmap(dl_df, docid, dl_w2v_model, dl_pca,dl_voc_dic, kw_size=50)\n",
    "    \n",
    "    content=[]\n",
    "    for f in figs:\n",
    "        content.append(['fig', f])\n",
    "    cards.append(['keyword map', content ])\n",
    "\n",
    "    \n",
    "    controls = []\n",
    "    controls.append( ht.Control_Select(id='docid', text='doc', options=list(range(dl_df.shape[0])), value=docid, labels=list((dl_df['fname'])) ))\n",
    "    controls.append( ht.Control_Select(id='topic', text='topic', options=list(range(len(topic_list))), value=topic_new, labels=topic_list ))\n",
    "    \n",
    "    return ht.HtmlTemplate('Text Summary App', ps, cards, controls=controls, page='deeplearningSummary').to_html()\n",
    "\n",
    "\n",
    "who_list=[w for w in os.listdir('text') if not w.startswith('.')]\n",
    "who=-1\n",
    "df=None\n",
    "w2v_model=None\n",
    "pca=None\n",
    "voc_dic=None\n",
    "@app.route('/lyricsSummary/<path:path>')\n",
    "def lyricsSummary(path=''):\n",
    "    global who\n",
    "    global df\n",
    "    global w2v_model\n",
    "    global pca\n",
    "    global voc_dic\n",
    "    #print(path)\n",
    "    ps={}\n",
    "    ps = get_ps('lyricsSummary', path)\n",
    "    #print(ps)\n",
    "    lyricid = int(ps.get('lyricid'))\n",
    "    who_new = int(ps.get('who'))\n",
    "    print(who_new)\n",
    "    who_str = who_list[who_new]\n",
    "    \n",
    "    if who!=who_new:\n",
    "        #df = lyrics_summary(who_str)\n",
    "        df, voc_dic, w2v_model, pca = lyrics_summary('text/lyrics', who_str)\n",
    "        who=who_new\n",
    "        #w2v_model = Word2Vec(df['words'], min_count=1, size=100,iter=20)\n",
    "        #all_keywords = sum(list(df['keywords']),[])\n",
    "        #vec = np.array([w2v_model[w] for w in all_keywords if w in w2v_model ])\n",
    "        #pca = PCA(20)\n",
    "        #pca.fit(vec)\n",
    "    \n",
    "    selected_lyrics = df.ix[lyricid]\n",
    "    \n",
    "    cards = []\n",
    "    #cards.append(['case', [['lyrics', '<font color=\"blue\"> Lyrics Summary</font>'], ['table', df[['doc','keywords','summary']]]]])\n",
    "    \n",
    "    content=[]\n",
    "    \n",
    "    display_detailcols=['fname', 'doc', 'keywords', 'summary']\n",
    "    for col in display_detailcols:\n",
    "        content.append(['text', '<font color=\"blue\">{col}</font>'.format(col=col)])\n",
    "        content.append(['text',selected_lyrics[col]])\n",
    "    \n",
    "    content.append(['text', '<font color=\"blue\"> Lyrics Summary</font>'])\n",
    "    content.append(['table', df[['fname','keywords','summary']]])\n",
    "    \n",
    "    cards.append(['lyrics summary', content ])\n",
    "\n",
    "    figs = keywordmap(df, lyricid, w2v_model, pca,voc_dic)\n",
    "    \n",
    "    content=[]\n",
    "    for f in figs:\n",
    "        content.append(['fig', f])\n",
    "    cards.append(['keyword map', content ])\n",
    "\n",
    "    \n",
    "    controls = []\n",
    "    controls.append( ht.Control_Select(id='track', text='Select', options=list(range(df.shape[0])), value=lyricid, labels=list((df['fname'])) ))\n",
    "    controls.append( ht.Control_Select(id='who', text='Select', options=list(range(len(who_list))), value=who, labels=who_list ))\n",
    "    \n",
    "    return ht.HtmlTemplate('Lyrics Summary App', ps, cards, controls=controls, page='lyricsSummary').to_html()\n",
    "\n",
    "\n",
    "mts_df=None\n",
    "mts_w2v_model=None\n",
    "mts_pca=None\n",
    "mts_voc_dic=None\n",
    "hasloadfile=False\n",
    "@app.route('/meetingSummary/<path:path>')\n",
    "def meetingSummary(path=''):\n",
    "    global mts_df\n",
    "    global mts_w2v_model\n",
    "    global mts_pca\n",
    "    global hasloadfile\n",
    "    global mts_voc_dic\n",
    "    #print(path)\n",
    "    ps={}\n",
    "    ps = get_ps('meetingSummary', path)\n",
    "    #print(ps)\n",
    "    meetingid = int(ps.get('meetingid'))\n",
    "    \n",
    "    if not hasloadfile:\n",
    "        mts_df, mts_voc_dic, mts_w2v_model, mts_pca = mark_summary()\n",
    "        hasloadfile=True\n",
    "    \n",
    "    selected_meeting = mts_df.ix[meetingid]\n",
    "    cards = []\n",
    "    content = []\n",
    "    \n",
    "    display_detailcols=['fname', 'doc', 'keywords', 'summary']\n",
    "    for col in display_detailcols:\n",
    "        content.append(['text', '<font color=\"blue\">{col}</font>'.format(col=col)])\n",
    "        content.append(['text',selected_meeting[col]])\n",
    "    \n",
    "    content.append(['text', '<font color=\"blue\"> Meeting Summary</font>'])\n",
    "    content.append(['table', mts_df[['fname','keywords','summary']]])\n",
    "    \n",
    "    cards.append(['Meeting summary', content ])\n",
    "\n",
    "    figs = keywordmap(mts_df, meetingid, mts_w2v_model, mts_pca,mts_voc_dic)\n",
    "    \n",
    "    content=[]\n",
    "    for f in figs:\n",
    "        content.append(['fig', f])\n",
    "    cards.append(['keyword map', content ])\n",
    "\n",
    "    \n",
    "    controls = []\n",
    "    controls.append( ht.Control_Select(id='doc', text='Select', options=list(range(mts_df.shape[0])), value=meetingid, labels=list((mts_df['fname'])) ))\n",
    "    \n",
    "    return ht.HtmlTemplate('Meeting summary', ps, cards, controls=controls, page='meetingSummary').to_html()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mts_df, mts_voc_dic, mts_w2v_model, mts_pca = mark_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [那么低的價值,, 但是如果政府上席臺太多,, 多一點的話呢,你搞不好也會丟,還是會丟掉,, 所以你這個呢也是瞞,瞞虧的,, 所以你生意策略的function,策略function,, 所以策略function呢成長,, 或是風險呢一些,你要注意一下., 所以還有一個就是,另外,另外那個就是那個,, 羅成那塊., 來不及這這產生了., 那這塊呢,, 這塊是你的市票要足夠,, 能夠去走出來., 因為你到時候,, 堂,因為他華漢堂,, 自己就這塊呢,他自己找,因為華漢堂的經營成本,, 他不會觸犯律法規., 所以絕對不要在河邊,就是,, 好像那個,就是,, 就是,, 你要去|去探,, 找出來., 你永遠呢,, 就是這一塊找出來的系統集成就是., 一定要比他另外一邊大,他是甩不掉的., 所以,你目標就是七三,, 那麼你已經獲利了七三., 報關呢,, |changes呢,反正,反正我也什麼什麼,我們什麼,, 什麼也都見過了,對不對,反正就這樣子,反正這個這個,, 是在在競爭嘛., 所以呢其實反而,反而我這邊呢,, 反而有很多強的地方是可以翹的,, 好吧,羅展浩,我們這來講這個,這個呢,, 反而做做事說呢,你那就是,那個就是，, 所以這個一定要把它做贏., 我覺得ID跟CD這塊一定要把它做贏., 我也會願意支持., 啊這,, 然後在周邊的話呢,, 就是要做considation., 現在把周邊呢,因為周邊周邊,, 還有,還有做,還有,, 周邊呢,, 這邊呢,我覺得那個人資,, 要,人資啊., 還有,, 那個,我們自己的這個部IT啊,, 就是跟上面那個,那個, 整個,整個,這個他除了,另外還有一個東西,, 東西呢,跟夏普的定位,還有相關的合作cooperation., 還有那些案子,因為是輕鬆并沒算上,, 哪個案子,哪個案子都要,, |是不是變瘦了., 不是有一點啊,瘦十公斤有吧?, 啊,有吧?, 我靠,你這是什麼牌子,你來抱我一下,, 抱一下喝咖啡.我操,你這手瘦十公斤有., 這是這是,, 我這是,我現在還有些沒cover到的呢,就是,, HR, 經管的,, 經管的能力培培育得太慢了., 對了,還有還有個傳統,得請求||那個政府., 政府呢是我們現在開始要做零組件., 的server., 瞞重要的., 跟我的,, 要開始,我開始做些sample., 做些,做些sample., 還有個,sample這個., 我們還有領土,OK,還有那個,, 剛講那個那個|,那個module,, 開始要做些module., 開始要做些,政府真的,真的,, 真的,今年他們一定要賺錢., 還要做這個module,第一類module,, 第一類module跟那個VR合作那個,, 我是覺得蠻有興趣,蠻有前途的., 那個大一類的,每一批都有,, 一定有好,不良品,不良品再把它歸類為||., 拿去賣,就可以把那個垃圾變黃金,, 這個是蠻好., 好不好,這一類呢,人人才去找,, |補貼可以通過你的connection,, 當我們客戶要合作,我們只是把這塊的一些人,, 合作的,第一個呢,, 我跟你講,第一任啊,如果第一任呢放你,, 放你,Jeff,放你啊,你覺得你覺得有意思,我跟你講., 你就會|., 這一塊呢,這一塊是有機會的,不是沒機會., 想一想好不好,這是., 試驗平台嘛., 對不對,這又回到你試驗平台嘛,我剛才定位在||辦公室,, 這個下去做了,你跟陳廠去,反正上下游嘛., 但是你要想想,這個可能., 新的生意模式,OK?, 的先鋒嘛,然後還有一個te technical的,, ||,這兩個., 第一個是一套的,這個要能保證., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1     [你如果是找那個,, 你是找那個誰,找那個,, 天瑜呢直接找那個,, 哦那個,, 管委會.張新港是吧?, 對,你直接找管委會,找這個程書記,, 直接把我們 education 的,, 這個,整個的計劃先跟他說., 為那個奧山的,, 那個學校,說不定也在管委會的那個,, 他程書記管的那個,, 武漢這個,, 就是他這個開發區的,這個裏面., 所以跟,就說,, 第一個是跟, 開發區下屬的,, 這些企業去做結合,, 也要跟開發區報備,, 這是第一個., 那這樣他的人,他也一定會,, 有機會,他會跟介紹給我,, 以後要擴展也需要,, 透過開發區去擴展,, 開發區這個教育,, 應該也是屬於它管轄的., 當然有教育主管機關,, 可是它是當地的,, 行政首長嘛., 所以呢,透過程書記,, 的這個,這條路,, 然後跟他講,我們有這些計畫., 然後當當做我們,, 在武漢做投資嘛., 因為你現在在那個,, 你在那個,那邊有大屏,, 對不對?大屏裏面有,, 這個軟硬件的開發嘛,, 因為你有 smart office factory education,, 所以,這裡面,, 就是需要一個試驗田嘛,, 這個test ,什麽 test bed,, 這個試驗床,對不對?, 所以你就跟他講這||的 education,, 我們大概期預計預計這樣做,, 這樣做的話呢,, 你就可以在裏面,就是有,可以有,, 你的培訓學院,培訓中心就可以設啦,, 在自己的地方設一個比較,因為你要,, 如果要做高級專業的話,, 在我們著,這個啊,, 湯遜湖裏面至少就可以弄一個培訓學院,, 弄一個標杆嘛., 當然也可以呀,就在裏面加一個這個,, education smart,, 啊 smart 那個 school,, 這個這個智能,, 這個教教育的,, 這個這個環節., 我們有四個環節嘛,對不對?, 那這下面的話,就是可以找天瑜,, 天瑜裏面說,人教版還是書教版,, 它本身就本身,它本身就有很多東西的., 所以,, 搞不好就用天瑜的這個裏面的,, 軟件的能力,加上我們 smart,, 然後跟周晉他們合作,, 在當地開發一個適合當地的,, 武漢,的這個當地的教育的,, 這個,所謂的一個,方案,, 哦所以,大概我的想法是這樣子., 好不好?這個就是講這個,, 哦 education., 有講說三個地點嘛,, 因為雲貴是不是,, 選一個地方在試水,, 這些本來就有幼兒園,, 並且關係很好的幼兒園,誰?, 之前不是有來了一個幼兒園?, 那個那那個後來後來弄掉了,沒有了,, 就是那個以前那個誰啊,, 以前那個幼兒園叫作什麽?, 後來不知道發生什麽事,然後就把它,, 把它取消掉了., 就是那個幼幼,幼兒園,, 那個幼兒園本來是跟以前那個余,, 以前深圳的書記叫做余什麽?, 以前深圳有個書記,那書記呢,, 他後來變成,, 負責那個南南,哦,那個什麽?, 南,南水北調的那個工程., 那個叫做余,, 我現在忘記了,他是,, 余,余什麽市長還是書記?, 後來呢,他的小孩子,, 他的小孩子,, 認識一個臺灣的人,結婚了,, 結婚的時候呢,他們就在深圳這邊,, 做,負責這個教育., 所以呢,, 這個呢, Terry 就給他一個,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "2     [唉,你可以看一下那個,右,左下角那個., 啊,中間的就是傳統的., 那個不景氣., 有HP,, 有Dell,, 有Lenovo,, 啊,另外一個就是那個,, 還有那個Aless,, Aless有幾塊呢?一個就是Watermaker,, 一個就是那個,Ill,ill什麼?, 啊,這是一塊., 然後|,, 這個也是一樣啊., 營收的,, 大的宣台., 啊,然後|,, 這個,, Starup,開始的, 有一shift,, 先談., 好多是,傳統的生意,那左邊的RID呢?, 也是一樣啊!, RID呢,那個, 所有的這個組織呢,, 我要非常清楚,, 統統給他弄清楚,, 包含Computer car, 啊!包含Computer car, 然後包含那個,嗯., Smatake,, Infocus,, 好不好,這些東西那個,要學IT的., 那vikoo要放進|,你們自己放., 剛才右手邊我剛剛已經講過一個|的manufacture,, |也是|,因為|他只有兩個,所以他|的|的那個,昨天,那那天談的,, 唉,你在不在?, 跟|談的那個,, 啊,所以他那個,, 是要排一下,, 你指的是他,, 剩下兩百萬臺的時候呢,, 當然你現在要去拿,, 所以你要串一下,, |那個是不是有這個Lenovo的?, 啊,|是他|給付富敏,, 就是|的那個sever, 啊,這是一種., 啊,兩個|并成一個., 那這樣還會賺錢., 還是并回來?, 把它放在那個什麼,, 啊,放在那個,, 那個,, 那個,, 所以這個要去做,作為一個studay,, 啊哦., 然後再就是,, 啊,|,|的組織規劃,自己,|的組織規劃., 然後你把那個策略投資,把它強化., 啊,那這同時裡面還要再做一些上市的管理,, 還有周邊,, 我要講一遍, 自己本身的組織,, 做組織規劃,, 組織規劃是全部的組織規劃,還是|自己的組織規劃?啊,全部都把他弄過來,周邊, 所有投資,所有投資,, 裡面含現代策略投資,, 跟|,跟|,, 這些組,這些這些組合要重新檢討一遍,, 周邊也含在裡面., 好不好?統統在這個地方., 哦,像那個斯,, 哦,哦,那個|,, 跟那個啊,, 拖進來., 然後你可以幫忙做., Seven你可以把,Seven你可以有一|,有一部分拉到,, 這個team裡面來啊., 啊,因為他現在Loading., 他現在,他現在,航空母艦Loading只剩下 一小小 一小小的他媽驅逐艦,他媽的有點累,有點他媽浪費了., 好吧,你把他拉進來., 哦,你把他拉進來,在我們,在我們裡面., 在你這邊., 這樣你會你會比較,, 那他的問題|,他現在就是只做EMEM嘛., 你現在,它主要就在ELEL,, 對不對?, ELEL,, 還有什麼?, 還有GL,就是這樣子., 所以他Loading還,好沒有滿., 絕對沒有滿的啦,, 所以他跟那個,, 的那個|,, 跟那個啊,BCG, 就要趕快那個., 好吧,CY那個什麼,那個,那個,你要跟那個conment那個的,, 定位,如果他是做,, 因為|有一個叫做,, |,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3     [這次呢等下我會找Hanson,,  Hanson去可不可以讓他借借兩個人過來., 那,這,在在外面找人是一定要做的., 這個是啊., 就是現在我們的一個,可以說是, 你現在是,你現在跟我講說你現在需要什麼?, 你現在,你現在是要找人手., 你現在人不夠嗎,還是?, 讓他直接request., 這個是現在的組織啊., 那,是這邊的話其實, 可是現在沒有人., 我需要PM的話就這樣我們只有一個., 做所有事情都其實他在旁., 但是為為什麼?, 就是說啊這個,很多時候都是浪費時間在說., 很多事情要Follow., 一個最追討流程呢,就是要注意那些,, 所以現在就是都是到現在做., 那, 系統systematic現在還, 在外面等一下我會跟你,, 在這裡講是tolerance., 那什麼樣才要說是真,這這個,, 他是事先沒有人來測試的團隊了., 那那邊也是,現在是,有可能,, 可能要,要要要帶,, 其實tester的話那林博那邊可以,對,可以提供., 等下,你現在你第一個是九分之一嗎., 這九個裡面你才有一個人., 然後十四分之二,, system degration., 十四個人才要兩個人,對不對., 然後Big data，, 這是特派一個人過來幫忙而已.,  現在,因這團隊是做他們的事情.,  所以事實上你只有一個人., 這個不是,這個這個其實,, 就big data方面他們做自己的Project.,  就,最主要是做他們自己Project.,  我們把它建設以後,,  AI應該對支持 large code,, 跟Dell放在一起的., 沒有DELL,就沒沒有key., 那你現在需要多少人., 要這一個就夠了., 這個其實就,就我需要的是在這邊., 你要在deep learning的,,  還有這個Support人嗎., manage,manage., Support七個裡面你一個都沒有?, 那梁博你們在哪裡?, 梁博你在哪裡?,  key在那個deep裡面require,對不對.,  是不是.,  都沒進展,反正反是., 一個人解決也就是這個樣子了., 那另外方面也跟,剛剛談過就是說,,  如果我沒有這麼多data的話,, 我的結果會是什麼., 好,那這樣子,, 你趕快做吧,就是那個,你要兩千五百小時.,  Terry的那個data,對不對., 你現在趕快弄啊., 你現在剛好搞起那個., 請那個誰,請那個., 請,請那個., 你要跪啊,你要,跪祖孫一樣把他跪出來啊., 沒辦法., 他叫我跪兩兩千五百個小時,我也跪跪跪那個,, 好,拜託給他., 給給兩千個小時., 但是你們,趕快做完,你剛,你你如果都沒有做完你你你,, 我覺得昨天講的你為什麼沒做完呢., 你現在做了什麼事給我看看., 是誰來做., 你覺得可以,你為什麼不自己去,, 就跟著他一起寫呢., 你說不自己寫你怎麼會寫得出來呢., 他更不知道你的狀況你怎麼就委託他寫呢., 我們早上是跟他解析說我們的,, 你今天晚上可以弄出來., 怎麼可以自己的東西然後叫人家幫你寫呢., 你又你又abuse人家, 你幹嘛,你怎麼會abuse人家這種resource., 人家不是沒事干., 對不對., 你自己要去寫., 寫完以後你對,, 如果真是這樣的話就追嗎,, 那你就,你就自己追到好為止., 這這是discuss,你就要這樣弄的好., 那趕快給他,給那個,, 給市市長看., 給市長看完以後., 然後再趕快送給我,我趕快要送給那個鄭紅莫., 鄭紅莫要準,你要,你要鄭紅莫準., 對不對,兩個都要準., 對不對,你怎麼可以這樣子呢., 你現在,你這樣,又不是浪費兩天嗎., 我Mark,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "4     [&是,有問題就解,有問題就解決,ok,好,他如果閃爍就是暫停,, 結果今天還是什麼, 是週六., 早上八點半這會議,, |準備, 錄了沒有,盧浩,錄了沒有,開始錄了沒有,開始錄了沒有,好,為什麼還沒錄,為什麼還沒有呢?, 啊,我給你講,|everyday我就來這邊上班,你想|你不是跟我講,你沒有, 沒有那個嘛,那我來的時候你又不錄., 所以你跟他講,每一個我看你不跟他講,你不跟他講,他七點半到,他不會到的., 所以你一定要display嘛., 這跟跟|是一樣的嘛., 我們現在根本沒有display,, 媽|殺一個, 一定每個都可以用., 好不好,就就是get together., 所以這個早上呢,要有一個會議記錄,我準備,我的目的呢,我的目的蠻簡單的., 好,那我寫了一半又跑出來了., 所以呢., 反正有這麼多東西,還有你一定要, 好吧,你每天你給我寫你做了什麼., 每天給我寫報告., 八點三十分呢,你要從我手裡主持這個會議去準備,所以number one,好吧,還有哈,, 你呢,最好派出 Jeff Li, 你那個 team一定要跟他去,他已經有二十個人了., 你可以派出他,那就變成是,, 你就叫他做外包,你就叫他來., 你叫他下禮拜來., 並在一起,你就是, 週六要這個, 他昨天講一個事情,一個叫做, 那, 傻瓜買火車., 你知道嗎,笨的人啦,愚人啦., 買火車,他什麼意思呢., 他看到, 我是古代的人嘛,, 清朝的嘛., 他這是業餘的很有意思的., 我我們買的火車有在清朝,是在買了火車,哇,火車很棒,我買了火車,劉明傳買了火車,火車買回來之後,哇!, 他媽的不是買火車,鐵鐵路都沒有., 他要笑我., OK,好沒關係., 那我知道火車是今後一定要用的., 我知道火車一定以後很有用,好吧., 沒關係嘛,我先買火車嘛,反正我家是有錢嘛., 我先把火車買回來,我先然後再慢慢鋪嘛., OK,他講這是很好的,以後我們就說傻瓜傻瓜專案., 好吧,我們AI就是傻瓜專案,反正已經被人家看扁了., 咱們被人看扁了,, 我們還不要努力嗎?, 被看扁了., 看扁是,根本看不到你的存在的, 因為他,他本來就很叼,沒錯,他很叼啊., 他可以弄香信,弄一大堆,可是呢,他跟市場脫節., 他一樣做不出來., 他十年做個產品,他一樣賣不了., 他一樣沒賺到錢,, 他如果賺到錢他做事業處主管就好啦., 對不對., 所以他每個人都有他有有他強的有弱的,沒那麼叼., ok,所以呢,你要記得., 好,我們被人家笑., 你們是傻瓜,買火車, 因為你,清朝嘛,買的火車,人家看那火車,呼,買回來之後,他媽不能呼., 因為沒有沒有軌道,好吧., 人家在罵我們., 是不是,他在罵我們., 很難聽的,, 你你沒有感覺嗎?, 是不是,他叼得那樣子,媽的我不相信,雖然很簡單,但是他的他, 他的意見非常好,, 越是這樣,我們反而越有越士氣嘛,不是嗎?, 好,那怎麼做., 我同意的,, 就Terry專案呢., 我們要build到這個,, 他搞不好以後是|,誰知道媽的會有||呢, 可是呢這, 他, 他講,我們有這麼多,比如說比如說他有什麼,他有voice,什麼他有什麼., gesture, G E S T U R E., gesture啊., 我們也有, 什麼,righting,, 來,對., 請你把把這些, 你把這些喔寫一下.好不好., 寫了已經寫了.寫了已經寫了., 我我我這我聽得下去,我可以這麼說, 我現在這樣嘛,來, 我可以嘛,我是擺face嘛., 我們是可以自己講嘛., 我們可以自己弄一個特別容易懂得嘛., zero one,zero two,還是zero|更好,one,然後呢我們再two,那還有three., 來我們是要build這個嘛,build這個嘛., 來,所以我們要讓他understand, 這個整個的AI., 或是這個 build learning, 你是老是變成是D group, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "5     [開發了就知道它的使用狀況,, 你弄過來就知道我們這產品有多好多壞嗎?, 我們的供應商裝的好不好., 為什麼,為什麼,這是施工裝的品質有問題., 還是來料有問題., 來料我他媽就跟, SDP說呀!, 你跟LG Samsung說呀,你他媽盤你做得東西有問題., 都可以控制呀.這樣的話.我們做品質才會好., 喂,我就敢跟他, 我如果這樣的話,我不敢跟他收錢., 你說是不是., 我們做Test沒有收錢., 喂,OK,對不起,對不起., 我們,趕快趕快弄., 對不對., 好不好,所以, 玩玩,回家了只是., 就要把他做做出來,就這樣子吧., 我今天就大概這樣子., 左邊這邊這邊., 交給我,好不好., 以后就不要存repeated一直加加加., 變成我們自己的一個, 至少是一個白皮書,發展的一個藍皮書,白皮書一樣., 好不好., 有一點我要提醒你,就是說其實., 開發的跟運為的要., make sure大家, 這個這個分工要分得很清楚,要不然的話., 會會會會., 他他他應他., 做operating的一定有一個人啊., 你們要|他., 不然你怎麼知道好不好., 對不對,就是FreeBSD, 你不能只有開發嘛., 生產到在,在做你這個Team, 又要跟又要跟那個誰,Jeff., 假設你是,假設你是這樣子,, 你是這樣子., 喂,, 好,那我這里有, marketing., 這是我自己我自己的看法., 因還沒有做marketing., 好不好,你也要這樣., 你自己來定嗎?, 喂,完了你這邊呢?, 橫向的,, 下面的是,就是., 就是CEO., 這是project 對不對., 還有CEO的這個., 哦,的這個., office的,喂, 這個offens major,, 不然你這RD就變成空空的嗎?, 好,那這樣., 這邊呢?, 就是kindle, 對不對,這邊呢?, 就是Jeff., 可以吧,可以., 那這個呢?, 對不對?, 這樣子嗎?, 好不好?, OK,那他們呢?, 他們,這里., 這里就是靠你來串了., 好不好,我就不想太復雜了., 好不好,那這是., 這是, 喂,, 這是,, AI嘛,AI., 可以吧,可以可以,對不對,就就這樣大家都清楚了吧!, 如果是group的話,那另外一個就是., 另外一個就是是為了資訊長., 喂,那個誰,那個., 那個呀,Jason, Jason呢?, Jason, 哦., 這樣子呀., 不要小事., 你可以看他,看他不見., 因他很難合作的., 他很難合作的., 你非常難得做, 所以我老實和你講., 這事情他繼然沒有人說., 他講是講,但是他做他現在沒有人做., 對就這樣,所以他是這樣的., 所以所以,, 按鍵是對的,因為他媽的,, 不缺嘛,傻瓜,我先拿到兩百兩千五百小時再說嘛., 你不直說,他怎麼給你呢,他給你他媽的,, 他有幫你嘛擋在那裡,對不對., 會后不知道呀., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "6     [所以,所以這邊的話是| Keys,,  剛才為什麼借弄不同的Keys., 對,這是白人嗎,那個白人., 然後下面是|., 因為我現在,要記一下記一下., 別說我到時候||., Moma, mony張是誰?, 他是臺灣人嗎?, Steve., EMC server加L ten啦., 然後L ten  GCD,Group., GC,, 那Mony那個Mine那什麼., Mony張,Mony張.是不是,SL, close line of business是含什麼., 但是,所以說.他是跨,, 所以他的,, 所以,這個所以,哦這個., 所有這close line of,, of 什麼?, of business是所有., Desktop,notebook., 所有的零零零組件都他買的,, 零組件都他買的,對不對?, 那那他是裝monitor在這邊對不對., 採購., 這還有group,這個Mine., 我等下給你這個好了., 這個採購是Mark., ||, Keys,啊Keys Mine,, mines., 啊Edward就他,OK., Kevin brown年輕的時候., 好,你算給我.這個這個||., 啊,monitor., 這個叫做Jorj., J ||, 好,那那,, 現在呢,就是,, 我現在就說,我們利用這個機會談一下., 就這樣組織呢,, 因為他,一個是談monitor., monitor因為你現在,他要他要,, 都說要對應那個Cindy., 從這,我們,我們他,我們的., 議題從這樣來的., 就|又去啊,都要去爭., 就是要,你是., 專門去應付那個叫做什麼?, Kefu.kefu., KKK什麼., KKKefu.kefu Till.,  Kefu Till.就說,, 他這Kefu了,所以你去Deal with., Deal with KF,那你現在要去Deal with這個Cindy., 但是你現在又,, 你你又這麼多東西., 對,沒錯啊., 那你可不可以,你可以專注專注對嗎., 你要找早就分身了., 你要找一個就分身.這是很很簡單,至少一個分身., 我們就我們就講講,, 講快點,就就讓人家早分身了., 很簡單,就這樣子,人家||肯定要人等,, 那,那做到說,, 兩個都能OK,其中有個人都自然接上去這就沒問題了., 你要有人,要跟Cindy對., 你說Cindy他,, 如果這個,這年紀多大,, 那你找,那你找個小鮮肉嗎,, 他媽的這個,, 給他***,英文又好,然後又可以媽的幫他,, 就這樣子啊., 其實你要你要這這這樣真要去打,就這樣子啊., 就拿去找一個,就專門這個,然後ABC也可以., 你知道吧., 我問你呀., 以前他媽的,那個誰啊., 以前那個Hawa就要做這個monitor的., 那,做,hawa林., 對不對,hawa林把他拉過來啊., 他在哪裡啊., 要要要人啊,Hawa不是做這行的., 不行,他是Sales而已., 他是sales,upped sales., 你乾脆把hawa拉過來給你算了., 對啊,那找他來啊., 找他來談啊., 反正沒有的話我也要解決,, 因為現在要review,沒有,禮拜二就會跟他碰面., 跟誰?, Hawa,人在哪裡?, 好不好,所以我覺得這要整一整., 我意思說,如果這這是一件事情,, 然後你要強化你的sales團隊., 那你看他要怎麼做., 你你整個組織要弄清楚,然後呢,, 我認為說就是,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "7     [這,在這個balance上面你怎麼去balance., 第一個,你也算是重慶人., 你先暫駐., 然后呢,你在海外的這個點., 怎麼樣呢,你所以你要去算算., 我認為你最好的方法呢,是你算算看., 大家的這個會,因為, 有這個|他愿意付., 因為他有很多high., the high touch, 對不對,所以這|呢,, 只要他這|他只有兩塊,一塊半的, 的範圍之內,比喻說這樣子,, 那沒關係,我願意付這個., 因為我跟他model是不一樣的., 那||呢或是, 他或是那個case他就有話去講了., 然後那個講了,這個沒有問題,我們會我們這樣,, 因為他有是個|什麼,他有一些|嘛., 他還是有這個|他可以去這個,他又不能, 去,拿回來一塊半兩塊錢., 是OK,所以你一定要用, HHP的|,我想大家分析一下., 這個GFO的., 整個|| N to N cost., 要去做分析., 尤其是HP|,, 這個DELL., 我知道不容易分析,, 可是你至少有東西可以分析的話呢?那他人家都沒話講., 我覺得這樣就可以說服了., 因為你這樣話,, 不然他|會一直||., 一定硬的時候呢,我們就不要累., 你要講殼子價錢啦,板子價錢啦,系統價錢啦,然後, 那就就扯來扯去的., 就跟什麼|啦,你用人用人數太多啦,怎麼樣., 這個人又來了,所以我認為是主動的啊., 主動的針對西這個部分去做去做去做這個., 讓他keep呢,, 因為Dell也不想去學HP,完全學, 他要我幹嘛我幹嘛去取喊痛., 對不對,這沒面子嘛., 我草我這|我是., 我是我是JIT的他媽始祖,我去學Dell., 不,我會學媽HP., 他也會沒面子!, 可能他也他,, 這因為他也不想學他., 可以一個有一個|,, 讓他去覺得說|我這個,, 各取好處., 我又,價格上我也有競爭力., 然后呢.我也有彈性., 那我就走我的位位位置., 因為他,畢竟還有|||嘛,又有high touch嘛,所以, 他,但是我們要給他||,, 這||就會變成說,我我們, 用中國的策略來支持他., 然后呢,做, 比較更緊密的, 區域分工,好不好., 我們在中國是支持他., 然后呢同時., 讓當他做,, 中國跟區域的緊密分工.寫下來好不好., 需要寫下來不?, 幫他在中國., 拿到解決方案., 幫他在中國建好機制.可以compet., 幫助., 好,幫忙Dell呢,, 在中國,, 有, 比, HP比HP, 有有有比有有比HP的, 這個優勢啦,好不好?, 所以呢.我就建議說,我們就在我們就在,我們統統在重慶嘛., 他在重慶,我去重慶,好不好?, 然后呢跟區域呢,, 跟|做, 更好的分工,好不好?, 各區域做, 緊密的分工,好不好?緊密的., 這是一個|,, 另外一個呢,如果你在海外呢?, 運到國,海, 從中國運到, 海外的時候呢?, 有沒有什麼東西可以在, 讓他做, 做更高的integration?, 然后在那邊做比較, 真正多一個,, 少一個兩個工站的touch., 也可以., 你總是要想一個,你總是要想一些., 方法,讓他有些話有句話講嘛., 所以呢你在., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8     [因為對我來講還是蠻重要的., 所以這個就比, 傳統生意的., 範圍裡面的,, 對,additional,對,Yes,Yes., 一樣哦., 對,它做法實際上是一樣的., 對對對,對,我們, 運用現有的 OD Model., 來供應., 新的client, 對,新的客戶., yeah,yeah,yeah, 對,yeah,, 我們,yeah., yeah., 而且有大屏., yeah,yeah,yeah....ok, 好不好,所以這哦這這樣我們就清楚了., 好不好,OK!這是Microsoft這樣這樣, 趕快把它弄好以後我們就趕快把這個組織填好., 策略清楚了嘛哦, 然後organization你要趕快fulfill., 然後那個basic plan要趕快報出來., 哦這是一件事情., 那另外就是說Once Chian ,one Foxconn這樣的||下面, 我們也要知道他們營收多少., 了解, 哦第十四頁, 這就是,, OK,要, 更多的detail.但是這個我我開始就share那個, 微軟所有的那個產品哦那個product., 還有就是現在我們做什麼?, 誰是做 L ten?, 哦,那這個我們, 是不是唉,額, 要做這樣子., 更detial的., 然後我們, 對,那我們會看到,, 對,對.我們那個哦,, 現在system都是那個誰在做嘛., right,現在system全部是PAK在做., service book,, 哦,service哎, service book , service proy, 還有service notebook, 沒有,沒有,service book 是tool  in one嘛,沒錯,我知道., 那service pro是開不了I understand., 它有做一個notebook嗎?對,有做一個notebook., 十三點五寸的.十三點五寸,這個應該是拿夏普的那個., OK., 那另外一個是service, OK,OK.二十七點五寸,二十七點差不多., OK,所以這個是有機會的對吧?, 那service help, 這也有機會吧?, hard know,hard哦., ho 額 holiday, holiday是那個?眼鏡., 哦,那個叫做M,, 哦,MD.哎MR., Mix額 ,Mix reality.MR., Your service plan,ok?, A service mouse., 哇,那,那暫時量都不大,你知道吧?, Service book, one hundred twenty K., What's that?, 怎麼那麼少?, Service Book., yeah., One Hundred Twenty and  Six Hundred., Only., 哦,額,service pro,  is four milion,four milion這是service pro,最多., 然後那個那個GTE的話是,, 是LTE,GEN額Gen,G是LTE, general額是第五代是吧?, G,G 五的六百K., OK,那service notebook 是, 它是第一第一代嘛哦,五百K., Service Studio., full in one 五十K., service hard., 一百K., 一百K我覺得有點夸單,夸夸大啦., 它賣的很差., 幾千K而已., 不對,幾千臺而已,不是幾千K.幾千臺而已., 那holer呢,只五十K., Service Plan., 有那麼多嗎?我也是有點,, inno away., 哦,OK,OK., OK., 哦,我可不可以多加,你是不是買一只||給我?, 你要不要買個service., 對啊!, 叫那個幫你幫你畫., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9     [B to B自主品牌,, 專注在smart office,, 新生意模式與, 對終端,, 用戶之價值創造,, 所有我就說我現在有smart ,infoucs,跟夏普., 我現在做的,, 那這是第一個|,就是,, 雖然住在這個|,然後呢經營經營, 好,價值, 生意生意模式創造,, 對終端用戶之價值創新與, 渠道之經營,, 好不好,渠渠道, 我們在在在判斷啊,, 因為一個是新生意模式,, 你知道我現在這個新生意模式我去做,, 我剛剛講說那個,, 還有對終端用戶之價值創造跟取道的經營,, 新生意模式,, 然後呢,, 新生意模式,, 渠道經營的強化好不好,, 嗯,好,, 你可以把online|,, 所以說, 間接變直接馬上., 新生意模式,, 渠道經營的強化,, 與對終端用戶之價值創造,, 好不好,, 好,這個是這個是這個是我們新把它定好,, 那你用這個|你要怎麼去弄,, 好不好,那個 tony有什麼意見嘛,你可以直接說嘛., 好不好,, 這是我們策略發展 B two B的自主,, 自主品牌,, 好,那個專注在smart office, smart retiring ,新生意模式,, 與, 渠道經營,, 哦,或者說,, 渠道經營的強化,專,, 在smart office ,smart school ,smart retiring 渠道經營的強化,, 新生意模式渠道經營的強化與,, 對終端用戶的價值創造,, 三塊把,新生意模式,, 渠道經營強化,, 還有要有|,, 就是這樣子,, 好,那,在三個上面,smart office ,smart school., smart retiring, 還是你把 smart retiring拿掉,, 也沒關係,, 以smart office 跟smart school 為主,, 好,那這個 retiring這樣就好了,好不好,, 因為這個有點不大一樣,, 強你強調兩個也沒有問題,, smart retiring,我只是,, 有這個渠道我就順便辦下去而已,, 在office跟,, 就兩塊,office跟school,兩塊,, 因為office school是因為你,, smart 就是education., infous ,就是 smart 跟夏普就是這個,因為,, 自主品牌的話,專注在三個品牌嘛., smart., infocus跟夏普,, 哦所有我們就專注在這個三個品牌,或是未來自創品牌,, 哦,這自主品牌,, 發展自主,, B two B自主品牌,, 專注在smart office ,smart school, 的新生意模式,, 渠道經營的強化,, 與對終端用戶之價值創造,, 那我們我們這樣的話,是屬於是屬於哪一種生意模式呢,, 就是,, 這樣的話是算什麼,, 是算,, engraving, Micro., 還是那個什麼,, 那個,, 什麼,跟美國那個||比較像呢,, 還是跟誰比較像,, 我們在想發展 B two B 自主品牌,, 專注在smart office ,school., 之新生意模式,, 渠道經營的強化,, 與對終端用戶之價值創造,, 為經為經營之,, 目標,, 好,成為中國,, B two B什麼樣的一個,, 這個,什麼之類的,, 好不好,大概是這樣的一個一個東西,, 可能要找一個,, 找一個,, 可能我們要去找一個,那個|,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "10    [tony, 哎,我們下禮拜把那兩面想一想吧,好不好?, 好, 第一個是smart test in the in focus, 好吧,到時候就一起來聊聊吧., 所以他才會 no see money., 對不對, tony同意吧., 所以我覺得我們應該想兩個, 應該會怎麼走是最好., 關鍵是input他是沒辦法被, 那個就唸,, 你搬不出這個solution嘛., 他他講講白一點就是現在是沒有什麼,, 就是你要|run的話,你的計劃是什麼?, ok, 來下週我們談這個話題吧., smart沒有什麼,smart他們自己自己負責的,沒有沒有什麼不能干的.&對對對., 好,所以說, 就是, 這個, 就是在線上貴, 十二點以後,, 要在主板是, |要推到主板, 對,所以我的目標就是破例到十到十五億., 所以呢,我們策略是,, 發展自主品牌嘛,因為剛剛前面談的,OEM,odm被他殺價,每一個要求都,他媽的,他以為錢那麼好賺., 一些要求你cost就是五十個million,他媽十四個million., 我哪有那麼多錢., 所以呢,現在只能擋一下., 所以呢,我說經常能擋就擋., |,但是我們還是要去加大力度去搶訂單., 穩住有個base, 所以| test發展B two B自主品牌專注在smart., office, 之新生意模式, 渠道經營的強化., 與經與, 對終端用戶,, 之價值創造的經營目標., 為,還有加上這個, 售後服務., 跟|recycle, 成為循環經濟,就是作為這個三C產業循環經濟., 中國的一個標桿企業., 那你要去找類似的成功企業,來自己模擬看看,到底什麼是可以最好的模擬, 好,所以這是一塊., 第二塊呢,我們現在經營的主體,, 是smart, | infous跟, 夏普, 所以呢,他們最喜歡|||我們什麼東西., 我們的資金啦,那些放款給我呀., 因為他沒那麼多resource, 他最喜歡呢,||我們的研那個什麼, 製造平台嘛,採購平台等等., 但是我們也, 我們要對他們有, smart office呢,, office就是坐在, 這個所謂的collect, 然後呢,這兩者我們都要加上AI跟, 那這樣的一個cycle, 一個一個cycle呢, 我不需要什麼都做,但是要掌握, 這個核心競爭力跟價值., 好吧,這是我們整個所有, 跟目標,所以這個||就要開始去把他規劃出來., 針對這個部分去把他規劃出來., 那去把你的營收, 去把他規劃出來., 然後,然後在就是說你有什麼需要的資源, 好吧,你來提出來., 好吧,我們就這樣這樣一直在這樣的一個cycle來做, 然後呢|,那個什麼那個就是那個AI跟|的話就是那天講的那個什麼,你把那個, 你把那個, 這個教練在負責,教練你把我那天新畫的那個刪個圈圈嘛., 還有一個框框,有沒有,對對對對,你,, 對不對,你發給那個tony跟那個喔喔 Eric., 相關的事業單位主管,, 好吧., 可以嗎,好吧,大家有什麼意見他可以弄, 對,可以講一講, 好吧大概是這樣子吧, 然後呢,我們現在呢., 在講的這個, 這個裡面其中有一個, 東西是蠻重要,一個是, terry的這個smart office的day to day, 對不對,所以我今天有講, 你day to day的話呢,你一定要把, 最笨的方法呢,你在這邊上班都裝了監控器, 然後呢,你這一百二十個|,每天使用的狀況你都要給我給我個回復., 到底他|去做去做整理, 然後呢,這次, terry跟這個, 你說想辦法去把他弄, 像這個你可以弄啊, 像你這個可以賺錢,你可以可以跟的士賺啦, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "11    [|, 你這是有點他你,, 那我們也不可能,, 到時候兩個都可以,, 你是外面,他是他他正在run,, 可是你有成果的時候你也可以進去,, 好不好,所以說是一體兩面的,, |,那我的想法是這樣子啦,你可能,, 還有工業自動化,, 機械人及物件,, ||製造,, 跟物聯網,, ||製造是什麼東西?, 你看他的,他投資的行業里面有一個智能製造嘛., 醫療技術,, 高端,, |,那個什麼,, |,系統換元件,, 先進材料,, 環保技術,, 廢物回收,, 所以這個,, Eric,, 我講的就是這個,, 環保技術他做recycle,, 那歐洲有沒有什麼東西可以我們給他買過來,, 放在我們這邊,那我們這邊可以,, 你就是符合他的嘛,, 你是,你不是中國籃球,你是香港的,, 那個叫做什麼,, 創業板,, 好不好?Eric你可以從這個角度看,好不好?, |, 不曉得你那邊有什麼看法沒有,, 我們專注在智能製造跟,, 環保技術,, 上面,我覺得他講的那五個圈圈只是它的一個口號啊,因為他現在只投了三家公司啊,跟那五圈圈一點關係.沒錯, 那你看到他的那個,所以他手上并沒有project,, 漢德投資行業的第六業,, 漢德投資,他他給的., 可以啊,, 我只是想說,, 他有資金嘛,, 那可以,他可以補我們要的,, 假設好了,, recycle是我們要的,, 那我們可不可以把recycle,, 引到我們自己secure take裡面來,, OK,, 因為,, 好,你可以問他嘛,, 好不好,, 私募的意思是,你可不可以解釋一下,, |,OK,, 他是限定在,, 這個德國,歐歐歐洲小型企業,對不對,你說私, 這麼說私募叫做private,, equ, |equity equity是什麼意思?, 好再講一遍了,你第一個講的什麼,不能超過十Percent什麼,什麼叫fund,什麼什麼fund,, |,OK,, OK,, 好,這樣這樣我就知道了,, 好,那你今天就可以用這個去談,好不好,, 這第一個,, 第二個呢,你去問一下那個,, Jim|,他們在歐洲有沒有什麼一些相關的標抵物可以enhance or enable他們在當地的能力,, |||他們,, 所以說我們如果,, 第一個是要找好的,, 轉型的標抵,, |這跟,, 就是把這個message要仔細查清楚|,, 第一個我透過這個漢|,, 漢德,, 資本來,, 來訪,老大,, 把他這個歐洲的這個老歐男,, 他又被被提出來了,, 所以我利用這個,, 漢德來訪的,, 這個機會,, 就跟他講說,, 第一個,如果按從第一個是他本身轉型他有個資料進來了嘛,你看看他本身有一個資料進來了,所以你去給我update,這是一件事件,所以eric你看一下,, 你看看他,, 有沒有當地,, 一些東西他也可以去做acceleration,然後可以加速他,, 做有,, 做加速他做轉型跟做價值創造,, 的所謂的,, 一些投資,, 或是並購., 好不好,那,, Eric,你把這個東西變成一個小小的像我們這樣,, 這個叫不叫做漢德資本,叫做,, D次,, 幫助,, 捷克轉型,, 然後或者是說做轉型,, 或是這說,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "12    [|, 他有兩百天呢都在做這個事情,, 我相信在未來的這個一個月,, 到三個月,, 這段時間是,, 會很密集做這個事情,, 所以讓大家知道,, 那這個也是我們第一次呢,, 我們D次一直都沒有增長的引擎,, 營收增長的引擎,, 雖然我們獲利是維持,, 但是呢,沒有增長,, 營收沒有增長, 的話呢,你要增長的那個engine,那個|這個,, 動了沒有,, 所以這個是我們|,, 所以FAE呢我們會拉很多人力去做,, 現在呢,是我, 自己, 做, 包含那個|吳,, 包含||,, 策略長,, 做品牌,, 行銷,, 那產品設計呢,, 沒有人,, 所以等一下九點鐘會跟Chris, 來談產品設計., |,那|所以我們現在要品牌行銷,那我,, 我剛剛昨天有跟那個,, |談,NTFK, 他提了六個問題,, 就我剛剛送出去的,, 我送出去給|,, 看看他們的意見,, 意思是說,第一個我不會我也不懂品牌,, 所以|我有CC給你,right?, 對,這個你要報studying,, 還有六個topics,, 因為那如果這個不清楚,, 他從,他的|,, 你的target,, |, 你是你是做什麼的,, 然后你的|||||,講的很清楚,, 如果這不清楚我們就做,, 那就這個,我覺得這個是有這是有science的,, 就是有science的,裡面有這個東西我們|,, 我我也會怕,, 而且呢,這金額都很大的,, 你找了|||是不是對不對我也不曉得,, |||都是我自己私人做的,, 我們D次做的,, 好不好,我想跟|,我覺得品牌這個東西|就是一件事件,, 所以呢,這個D次呢就有一個,, BTV的||building一個,, successful的B TO C的TV的, |in USA., |這是第一個,, 那也會跟,, 這個TFK講,, 如果沒有的話,我認為,, 叫他們做一個BTB的||,, |in USA., 一樣的,, 我有BTC跟BTB我都做,, OK,所以我就知道了,因為我從這個地方,, 如果|就問他個||, 如果他沒有辦法回答問題,我知道你|, 你也是||,, |你也是,, 不見得是懂啊,, 我用這樣來驗證也可以,, 那我用這個機會來學,, 好不好,至少我清楚,, 我認為如果說我需要花點錢,那我認為說花點錢也值得,好不好,這是第一個,, 這個呢就回到我們當初講的,, |, 你記不得的我們上個禮拜就有講了,, |, 發展自主品牌,, 好不好,我當初講BTB嘛,, 你記不記得,所以發展自主品牌BTB然後再加個BTC,, 一定要做,, 好,這是第一件事情,right?, 好不好?所以,所以呢,, 所以這個在這個情況之下,好那我就講了有什麼事情要做哦,, 你看有多少事情要做,, 品牌要建,, 品牌要建的時候呢,他要做什麼他每一個event,, 我們現在一個一個講,我把|講完,, 每個event都跟你有關係,, |||去的話他每個|,, 都要做視訊,, 白板,這個你知道|來的,, 你就每個都要跟他收錢嘛,, 即使我們到了那個沒有|,你也要||,, |,好那他有幾個疑問,, 第一個疑問,|,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "13    [梁博啊,梁博,你的聲音斷斷續續的啊., 你可能,你們要,這個會議結束,你現在是對着,經常對着他講., 結束以後我希,不希望再看到這個., 你們自己去找,找把他弄好,好不好., 你自己使用者,user你都不care,那別人會很辛苦的聽你講,這樣效果就差了., 所以對自己的部分,如果對方有不好,你就趕緊哎你那個音音音,那個音響效果,音效收音效果不好,講出來聲音不清楚., 你就互相,互相嘛,因爲我本來就是,再這個是關注我們的一個,一個我們要建的Echo system,對不對., 所以要把這個東西,自己如果是不好那就趕快改嘛., 還有呢,我聽到你後面有background,bec,background 的聲音,你在哪裏啊?, 還是你要換個地方了嘛., 還是叫旁邊人叫他不要講話., 對,那爲什麼Echo呢?, 我,我看看,有沒有全部都放mute., 攝像頭最左邊那個叫什麼?, 那個做基礎,那個,, 那個左下角., Jason你,你是不是你那,你那,你沒有放mute?, 好吧,那請繼續., 我問你哦., 我覺得,我能,我能理解|,就,, 這個東西呢,要非常清楚的跟對方說清楚., 好,我問你哦,如果說可能跟專案需求的方向不同的時候你是不是應該|., 我們就開始重談了,||有說,這個,這個不行., 所以你要給他壓力,我覺得我們沒有給那個Mike壓力,一點關係都沒有,我們沒有給Gramlabs那個壓力的., 你說語義理解根本就沒有,我們,我就,我就不,我就,我就,我就這樣子不行啦., 你設麼時候可以強,將recovery回來., 好吧,我們要有個KPI嘛,至少有個index., 哦我現在講到這個是有關於這個,有關於就是我們跟對於這個surprise之前的要求., 不然怎麼控制他呢,好像我們教育他做., 供應商,哎,供應商你又做不好,我要跟他講., 那我們有這個,有沒有., 他要不要解釋,所以你是不是,所以你就要讓你,接了也解釋其深度學習技術的架構., 有沒有解釋,那我問你,那他的深度學習架構是什麼., 梁博你再講一下,我聽不到你講什麼., 語義是不是最難的部分?, 那我再問你啊,他採,架構採用類似Amazon Echo的命令式語句., 可能與專案需求不同,那你怎麼知道他是用Amazon的,呃,架構上採用類似Amazon的Echo的命令式語句., 那我問你,他還是說,這意思是說,他是用Amazon的架構呢,還是,, 還是他用Amazon,Amazon所有的open資料的這個source code,你可以去比,自己去改,變成自己的procreation., 哦,那我問你啊., 如果說可能你專案需求方向不同的時候呢,表示說我們當初投的錢是,, 那我再,我再重新那個弄用另外角度問說,如果是這樣子的話,是不是,, 我們,應該,也要他瞭解他的技術架構., 我們跟他participate進去,這樣是比較合理., 是不是可以做到這個要求., 對,其實呢,或許呢,到這個時候呢,我們可以., 因爲呢,現在Amazon呢,, 我們講Echo嘛,因爲Echo要講英文,對不對., 那如果說,同樣的,他也是用,, 你要用那種,句型,讓他記,就將來就可以省掉很多,, 應該講,越簡單越好的這種,越簡單越難., can can掌握的他的意思的這種,或是指令的這種instruction., 可以,比較容易identify., 所以其實,這個是合理的., 因爲Terry他想去做,他Terry想去用Amazon Echo., 他在家裏裝兩臺., 所以他也應該有點., 但是你要把他這個階段性,因爲現在你慢慢會擴大., 所以你也可以說,我們目前第一階段是屬於這一種的., 那我們後面還有沒有做|., support這樣的話,那這樣大家都可以接受的., 那我再問你們哦,Joe,因爲他,沒有解釋其深度學習的技術架構,, 同時他現在清楚也很落後,, 我不會要求他., 所以,我說,這個,, 我,我們要participate的地位., 那我們有沒有人,有那個能力,跟他一起cowork., 我的意思是說,有沒有,不,不要說,我這樣,|有沒有||呢., 我們只是沒辦法看,還是呃這個,在其|||嘛||嘛., 他媽以後我們是要的時候都要找他., 我操,我他媽累死., 對不對,你你總是說我買車,那你更想一級二級保養OK嘛., 我一二級的這種東西我是可以做的嘛., 我總是要這個level嘛., 你不要,你有什麼事情都找,人家不管那個., 只有保養的,說,我用使用着這一個,這個,應用的這個東西呢., 我是啊,一,假設分成三級,或者分成四級., 是啊,第一級第二級我自己可以做., 三四的話我再跟你,再,再做開發., 再,再加,的話,那我再找你., 還是我知道我要我要,以後我提的需求跟process., 一種是有沒有銜接., Joe反正,, 沒有說,這個是,當初這個案子是他給join的,還是說security., 就說那你,就G就是Gramlabs一起嗎?, 好了,我們繼續吧., 這次要就要再,再,再., 請繼續嘛,繼續說,好,等等到你講完., 這樣子,|進來沒有,|., Charles你你那幾臺,你你那在那邊忙什麼?, 好吧,那你先go吧,你先go吧,你先go吧,你先go吧., 你講一下,京東,做過誰., |補充了,Vinson這樣子哦,我,我們也,, 我們現在手上呢有smart, factory,, 跟office爲主要的一個focus., 這裏面有很多||相關的事., 所以我想呢,再跟你談一下,, 這個組織的未來發展的策略方向., 好,然後組織的部,部建.]\n",
       "14    [他這個呢就是叫做,, 他這個,可能就是,, 做那個叫做,, Amazon的那個Fire Fire TV., 所以呢,你Fire TV這一個事情., 還,然後另外是Fly |., 還,然後呢,另外一個就是,, 這個solid OEM., 這三個東西., 所以你先把這一百個萬,, 跟,三十五,但你也有四十跟四十五,, 六十,七十,七十centimeter就OK了., 好不好,好,這是一個事情|,我再,我再往下繼續講|., 所以呢,我先往上走., 往上走|,, 等一下呢,那個誰,那個你幫我弄一下|,, 那個,你幫我接周律師., 我接周律師的意思是呢,, 是IDC跟BCG,, 還有等一下我們|., 我發現了他們太貴了., 朝|||,你知道嗎?, BC架構收多少錢?, 我說你他媽二十個million到三十個million., 都要付的,是吧., Twenty對啊,就這樣., One|one|million dollars,, Million dollars., yeah twelve||is a||., 我一般我跟你講,, 我知道我找|,我找||., 對不對,所以呢,, 所以呢,我現在這樣子,, 我就透過周律師去弄., 因爲我付給周律師,錢很好付., 好不好,我跟你講說,周律師您,, 我透過你來做., 我透過你這雙手來做., 我付給周律師,沒問題., 他也有營業額., 他是,我叫他,趴,, 他,讓他跟|掛上關係., 假設我要找|,我也可能找到他., 我說BCG,我有改善關係,, 他是,我說這是如果我要做律師幫助., |to|,從品牌到,, 剛剛突然driver,突然放哪個||隊的,對,我找他., 這樣我付款太容易., 我跟|按||付的話,, 我,比付給|快嘛., 沒有人會擋我嘛., 對不對?, 對啊., 靠,這,這招啊不錯,被被逼的., 因爲,我跟你,我現在坐在駕駛座上面., 我要知道我要付款., 不然我付不出去的., 那現在我覺得|., 或者因爲他裏面有很多pattern., 我覺得呢,你如果要做B to,, 你如果要做B to B的 business mode 呢., 其實這個裏面有很多pattern之前要做的., 第二個,這裏面很多data collection., 這個東西,實質上,, 他有技術的,他不是沒技術., 所以當我在build這個時候呢., 我就叫周律師給我|., Pattern不是只有設計纔有pattern., 供應鏈也有pattern., Supply chain也有,supply chain也有pattern,什麼都有pattern., Data也有pattern., 所以呢,我利用這個機會呢,我透過他去弄., 而且呢,如果說我找的supplier不好,, 他說,哎,不要找他,找他們., 他還幫我過濾., 因爲他畢竟他還是,他,, 他,他的,, 畢竟他的涉獵比我廣太多了., 他還做TV的調查., 他做很多automation的調查., 他做一大堆調查., 工會事情的調查,他join了很多東西的., 到底誰行誰不行., 好不好?所以呢你問他,你說周律師看看什麼時候,, 可以通電話的通電話,, 不行的話,我跟你講,, 我很想去找他,你問他在不在那個., 禮拜六., 好,這是禮拜四., ||||,禮拜四晚上到., 會議,剛剛講的你每個主管你也來報., 你的目標,你的objective,剛剛講,有的是,, 有的是,五號,像你就是五號,因爲五號就要開會了., 你要,把它定案., Agenda定案,誰要參加., 你的Objective是什麼., 你的目標是什麼., 如果是Terry十號要去看,看場地., 這場地的,你這個,最後的目標是什麼., 我都給你目標了哦., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "15    [那是住六十七十.事實., 好不好|,||., 那地方對,我們可以買., 那等會與||有談., 好,十號行程., 好,九號是這樣子., 九號到晚上., 晚上所以你,晚上那個盯的., 我可能被邀請,他沒被邀請., 但是,我要準備到那個||., 我們是有什麼問題挪一起,好不好？, 所以八月八號的,, 那個,八月八號的那個,, 那個||瞞重要的,readiness., ||你一起去,好不好., 好,十一號., 十號是,十號應該是行程這樣子., 他找||., 找那個Boss., 對,然後再來就是我們||., 啊對,這三個基因menace.對., ||., 企業,就是聯誼啦., 那十一號|就是跟government., 談這所有的事情., 然後晚上呢., 那個,|,||., ||跟Terry., 跟Terry吃晚餐.對., 這||是四十九歲吧., 我看他是一定要干的., 他無論如何一定要一定要做的., 我的感覺啊,我的感覺., 我認為這個案子呢., 成,不成的幾率|., 低於五趴., 一起投資下去., 沒的搞,他就投他., 反正Terry,我認為啦,我這次認為,, 我是,我是,當我這,, 當作我是胡說八道了., 我認為呢,他就投資美國., 政界就投一個人,是這樣子., 剛剛好問他就是那個||什麼,那個., 有派那個||壓住他,我操,, 他就,他就,他就,, OK哦,他網絡十年都OK., 這投資,他他在投資源., 我認為他要投資源., 之後呢,十二十三號的十二號呢,, 一樣,, 你在這個十號十一號如果沒有參加||形成的話呢,, 你繼續會告別||., 所以你一定要把你自己那個section的,, 那個你就,那個schedule要給我., 好不好,你不要跟著我走., 我看,一個是Terry schedule嘛,一個是我的schedule嘛,一個是你的schedule., OK?你不要都被他影響了., 你現在跟你,跟你沒關係了., 你要,你要把資料給我,我要把資料給Terry嘛., 一樣的意思,好不好., 這三個類的資料,, 然後,你自己的objective是什麼., 好,所以再上呢,在十四號禮拜五,, 或是出發禮拜日之前., 你原則上你要達到的目標要非常清楚., 你如果沒有達成,, 你就要繼續留下來做., 好,所以我七月四號晚上跟七月五號早上就要在這裡,, 你在十四號十五號做這個,, 這個之前,你一要完成你要做的工作., 要確定清楚,沒搞完你要做到,做到完為止., 好吧,這樣子啊,這是我,, 然後你的,你除了這行程之外,你要把你這個team的組織,, 你的team lead,組織你要有., |CY., team lead的以外., team lead下面的,所有人的人身安全,, 你要負責., 我要先,把寫下去哦., 好不好,你不要再問,幫我們,, 我們這麼大我們不可能管那麼多吧., 所以你自己的,, sa safety你要自己,, 那個team lead你要自己負責., 好不好,計劃好不好就這樣子., 啊,行程., &., 你的objective., 你要同我一起,好,這第一個., 第二,你的組織,, 你要,你要,你有自己objective,那做不完,, 不能離開., 第三個,你要team的,, 自己有自己行程以外呢,, 你要team的member,你要在care，, OK|哪怕是只有三個,沒沒關係,, 你是lead., leader的旁邊,如果leader不在,, 下面,嗮數目是誰., ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "16    [[Mark]你去確定就好., 直接對.我們對客人去賣,, 所以營業算我們的., 從 server | 的角度應該是要跟, 跟你一起合作., [Mark]因為我們不是只有賣硬體的., 以 sharp 的 || 來講的話, 它的 configuration,, compucast 不, |, 還還沒有證明是,語音開案做進去了, 對不對?對對對對對.那個副總跟,, |adapter.哦, |, 的那個 demo, 開始在開案, sharp, 也有興趣,對對對.已經開案在做., 足足少了三百多塊錢,, 所以大家儉省這三百多塊錢,可以把這三百多塊錢, 的這個 margin,, 這個這個空間可以用到其他的那個定價策略上面去., 你再講一遍,, 什麽? 哪裡省三百多塊?, 以夏普來講的話, 它是用|的., aopen的computing., embedded. 那如果我們用這個, 呃miniops form factor,, 加上一個adapter,, 可以用compucast就放進去了., 這整個solution,computing的solution,, compare現在在aopen,, 可以少三百., [Mark]你說aopen.aopen,aopen就是說它後面要背一個, 工業電腦,對,對.那是 aopen, 做.現在ok.那其他新的不要, 用compucast,那個可能三百多塊,compucast可能一百多塊就省了., 美金?對., 好, ok!, 你把這些個這個market,, 做一做,那你們自己去分利潤,, 因為你需要很多, RD resource,那你用這個地方去exercise,, 就你也看看怎麼,, 他們也要營收嘛,因為他有microsoft,, 所以你們跟他談., 因為以後呢,, 沒有一些,因為你有一些valueadd,, 人家才會不是|了這個solution,, 就是base on,, 就是 |||,, 人家這個我改改那這樣就做了., RD, 一個是,, 沒關係!其實,其實,, 其實呢,, 你把它放在一個一個籃子裏, 面嘛.噢!你放在一個籃子里,, 就你統統不要先,你統統不要,先放到一個,, 然後,到時候我再說., 好不好?不然你這邊弄一弄不就沒了嘛?, 每次都這樣子., 好不好?我覺得說,你看去create個東西business,, 這次buz是我跟人家合作都要去大賣,, 而且要賣的出色., 我跟你講,我我這樣說,, 如果你營收超過一億的話,假設啊,, 你這樣total超過一億的話,, 我就給你們拿獎金,, 我就給你additional獎金,, 好不好?弄這樣子啊!, 我鼓勵你去賣,, 好不好?你們自己定個目標嘛,, 你|做完以後,你定個目標,, 我要營收,我要營收就對了., 那create這種model,, 就是說我是, 提供這個education., 這compucast,把compucast變成我們一個, 一個亮點,不然我沒有東西嘛., 所以你就把 compucast 這邊所帶來的生意機會,, 你就把講說我這樣, 帶來的生意機會都多少錢,, 對不對?我賣了多少compucast,它帶來多., 把我們自己的這個, HW變成一個value |,, 然後customize, 賣出去,, 就這麼變成一個., 如果你有賣到一億美金,, 兩億美金三億美金,, 那這樣, 我我就我就, by percent給你們獎金,, serious!因為這個這樣這樣比較有意思嘛., 那他像那種越,, 我就是要是create new model, courage地去做這個事情., 我用你們sales的, |來當做你們獎金,, by percentage,, 好不好?, 這樣可以吧?, 好不好?你去賣嘛!, 因為你||就不用扯,, 你們三個人這加加起來,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "17    [聽得到嗎?, 呃,聽得到,聽得到., 呃,沒有., 好., 我現在講那個,FE呢,有幾塊., 一個呢,是,呃., 我的行程這一塊., Michael,你放屁,我靠., FE的四部份行程., 每次他要做螢幕,現在是23寸., 那做一個十五寸都已經燒錢., 燒到., right?, 那那那.那更大屏呢?, 那如果是這樣,他應該,他應該就是一直,會不會做notebook就好了., Notebook就是有十三.十五.-, 他現在有啊., 呃,十五寸螢幕有在做,但是還是沒有., 那你跟我說notebook準備幾個?, 現在就是在講這個,一直在講這個., 十五寸的,因為., 螢幕要先出來啊.我沒有那個螢幕., 對,他在做這個螢幕.那我們., 當然Notebook都是可以.Notebook, 只是那個,那個螢幕是customers,他的., 它的back和soultion., 上面它有一個有個叫做.., 它就是., 不是用現在的, panel和standard,它是, 它加一個|||., 那,那,呃,我們快一點., 那如果這樣子的話., 這個,如果是., 以後十五寸的話,那,以後十五寸就一種,一種模式., 對,所以這個我們要去., 你要去,像他說的., 我們先要瞭解他的商機., 那我問你,那如果再跟這個interaction呢?, 沒辦法,那個更複雜., 就是說,我們在講說., 三D TV,For example., 兩三年前,, 四五年前,哦好轟動啊,打開三D電視什麼的,然後呢?, 所以說是要掛眼鏡啦., 現在是裸視啦., 有的是裸視.那個但是你是要站在中央., 那個也是., 這邊的technology., 有的是,哎,你掛這個,然後它閃., 呃,那時候談得時候超過., 幾年前啦,超過., 四五年前吧., 好多買,那現在就因為., 所以,要小心., |, 啊,then., 到底有多少學校要來,, 買這個., 那他的solution, 都有它的content., 就是每一個人都要買,還是教室就買一台., 這個就., 我們要去,去., 再更細一點.我大概聊一下它的technology., |.另外這個., 再一個,這個這個,這個湯遜湖., 湯遜湖這個,那個,那個., 那個去昆山那個,, 怎麼樣., 因為我因為,, 昨天到昆山這邊主要就是,, 把昆山在|政府整個邏輯哈., 跟他們present一遍., 然後., 做整個,整個, 細項內容的比對.其實整個昆山的,的package哈., 呃,做的., 跟我們湯遜湖要跟他推的是,完全,百分之九十類似啦., 所以昨天,這邊政府., 政府團隊昨天跟他們講哦., 他們也蠻buy in這樣的一個idear,, 所以呢,接下來我們要., 是要把,要決定到底要放,工業富連網., 這個平臺哦,在等於, 昆山的所有物聯網科技城一樣., 然後它是把城北的,, 一塊两百畝的地拿來重新就是,, 重新改造., 哦,那,然後., 他又把城北的區域要再分三期處理掉., 把它變,把它變成一個,變成,, 工變成商貿,商貿這樣子的做法., 所以., 然後他再再,加上一些新的其它的項目., 在附近區域的,, 新項目,一個一個把它塞進來., 哦,那,這是一個., 整個package是這樣子., 那至於說,他們裏面呢,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "18    [我們把CE的策略跟生意模式,, 跟,, 作業流程先做討論,, 你們他媽的都沒這個你們怎麼講講繞來繞去都沒用啊把生意策略,, 跟模式嘛,, 生意策略跟生意模式,, 還有作業流程,, 就是執掌各方面,, 每個單位的執掌,, 跟作業流程是什麽,, 要講清楚.我我我覺得這裡面有一個,, |的,生意策略,生意模式,應作組織,作業流程好不好?今天把它弄清楚一二三四., |||||,, 叫那個sharp死,, 也是一樣到||||||||,, 一樣再來次,, 你有這個問題他有這個問題對他要報給,, 對不對他說他重分,, 對.那中間可能這個我就,, intel說market什麽,, solution market ready solution,, ready,, 所以我覺得這樣子哦,, 我們在在座的|||,, 生意策略生意模式,, 然後呢,去做組織,然後呢,產品跟解決方案., 然後呢,作業流程,, 這叫什麽,啊,這個東西,, 那你最好最好是你給一個計劃對不對,, ||一個計劃出來,, ||||||,, 運作組織跟云計劃先做出來,, 對.那你自己去弄一個自己的品質,, 這是營收嘛sales||,, 對我來講,, 對我來講我第一次發sales||你,, 我給你講過了,, 對我來講你怎麼賣東西到哪去,, 都來講,, 對對我來講,, 如果你這個東西你可以||||||||,, 不會是一百萬一百五十萬的營收|||||,, 因為你做這個,因為這個對于你來講,, 因為我們在這裡面變成是,, 從,, 變成是跟人家合作,, 把我們去,我們也都有點有點||,, 變成solution給人家,這樣你就有value,, 我就我就不是做OEOD的,, 你就轉型|,, computer card我就是|||我我做過intel,, intel的|channel,, 然後我們做成,, 解決方案,, 然後呢,用用我們自己的hardwre,然後變成解決方案,賣賣到渠道裏面去,, 這個就是一個新的這是一個新的,, 對我來講這新的有有module., |||||你就有|||,, 你去||||以後,, 因為你是什麽因為,, 你你來說,, ||||你是,, computer card,, 解決方案你是,, 跟intel去,, 變成partner,, 然後呢然而我們,, 這邊品牌的東西,, |||||||,, 我相信||,, 你的策略是這樣子,, 就是用我們,, 跟intel共同開發的,, 這個device,, 結合我們現有的產品,, 讓讓它變成讓它,而且讓它這個產品呢,, 就是好用,, 有valuate,, 這是我的|,, 這是我的估這是我的我的我的我的valuate., 所以,, 你們這個單位的secure take,, 就是想辦法就是在現有產品裏面,, 給予附加價值,, 做價值創造,這是你的以後這個單位的意意義,, 然後呢,可以幫他帶營收帶利潤,, 我們自己也有可以,, 可以||,, 因為我現在做,我現在把用他們的品牌,我變成公器轉夢,, 你的目的是你的設計策略是,, 公器把公跟器,, 轉成夢,, 這個solution可以賣掉,, 那這個是第一個案子,這個可以講哦,, ||||||||就是這個,, 這個大|聽得懂., 然後你你也通過這個然後你也經營,, 幫他經營||,, 就是你的,, 經營渠道,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "19    [major platform, 就,就就value., 這是,, 這樣的話||就知道這個, 這個渠道基準., 也不一定說,, 那你如果去走那個什麼傳統的, MB平台||不知道幹嘛., |就是把, 他的MB了,, 的|那個,, 另外一個我再舉個例子,, 如果是這樣子的話了, 那天我們|講,, 夏普的人要做併購,, 是正面併購,, 可是了我可以做反向併購,, |, 我|會併購我做什麼了,, 我跟他講我改個東西我想做,, 第二個就是,, 去買那個什麼額,, 你去查一下這個|cover嗯, cover它每一年收了幾億個, ||., 他知道是誰在用,, 對不對? 他知道是誰在用,, 那現在誰在用的時候了,, 他他知道誰在用,, 可是了,他用了, 他要怎麼佔據,所以說, 這些人搞不好有的是, 他要換機了., 你知道他是怎麼知道換機,, 你知道他是, 政府訂單,, 你知道他是那家公司?, 你就,你就可以你就可以透過這個機會, 來來*,, 這邊有是什麼情況, 你就可以賣了,, 因為這不是他渠道,, 完全不是他渠道., 他也他也沒那個渠道去去match,, 我就可以做這個,這個, 我就是品牌公司的經營,, 我就可以做這個., 這一家公司我真的想去買,, 為什麼了?雖然因為他是他是做中國跟,, 中國歐洲跟, 額美國., 三個渠道都有., 這個是我想買,, 可這個有個risk,, 因為in不願意risk., 所以我昨天跟他講說,, 我了因為||,, scan document,, 然後in the in the club,, 所以了我說我如果這兩個function了,, 我就不需要, 去買這麼貴的, 品牌公司,因為, 我這樣就可以value|., 第二個了,, 我若去買家公司的話,, 就去買這種公司., 就是同樣的從職性比較高的, 公司,差不多這些人都兩萬多個人, 一萬多個人,這些人你除,, 殺也殺不掉,, 這些人怎麼除,, 你還是有問題., 第三個擦除,, ||,, 我覺得他講的|,, 他說呢,, 如果現在這麼, high module的module, 總會有一天會被打破., 因為他們一直以為他們會賺得到,, 以後也是., 錯了,, 以後五年內,, print 的inject 呢,, 會取代這個A三值,, 會把你吃的吃的很慘., 因為如果只在這個|,, 所以|, 我覺得現在很危險., 現在我不喜歡做, BCG 的原因是因為,, 它都是用傳統的, 方法,, 在做併購., 你沒有辦法sustain, 五年以後十年以後,, 所以呢我覺得|,, 是還要能夠sustain五年跟十年以後|,, 不是只有|那個moment他屬於,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "20    [&, 而且這個呢Intel的是,, 第一次他媽的第一次的||的., Lenovo也是第一次||的，那不更快,, 好不好,做夏普在Valitation., 喂,所以這個呢這個麻煩一下好不好?, 所以如果是secure take這個平臺的話呢,, 那我就expected.,  我明年會有一些營業額,, 你給我越大越好,, 好不好,先就這樣.那你說我去找那個，, 什麽,什麽,, 那個我我自己|,, 我跟大家講一個例子|., 像這個|,, smart跟infocus的aging,, 他媽的,佳潔|,, 佳潔跟那個叫做,那個叫做恒,, &大恒,好., for instance,, 佳潔跟大恒呢,, 我的看法是這樣子,, 自己拿過來做,, 你可以講說smart跟infocus,, 他媽你不要談,我來談,, 你自己拿過來談,, 好不好,也就說,, 這個是我的控制力一定比他好的嘛,, 你不要開玩笑,你infocus既沒,, 既沒虧Design又媽的又那個,, 你才多少量,, 所以我才說,你跟他講,, 冠軍跟infocus在||,, 中國的數量,, 你現在是賣十,, 我很簡單,我加了十., 你跟他包,, 我跟你包,所以你把他拿出來做一個記錄,, 假設他賣一個十,賣十塊,, 他賺十點二., 你他媽你突然給他加二十八,, 你自己拿過來做,, 那個大恒那個smart也是一樣,, 因為我們這兩家是我自己七十趴,, 我說了算啊,, 我就給你就好了,fuck., ||他感動的,, 好不好,現在你就有東西了,, 我的意思說,你的渠道都是你新的,, 這個渠道你自己去跟他給,然後你自己去逼他., |你這個,你這個你應該很熟的,, 你應該很熟這個., 你這條線拿過來,完全有一百個折扣., 那這兩邊有什麽產品呢,, 第一個大屏的你也可以賣,, 你也可以賣solution啦,你也可以賣你的com,, |先不讓他,進嘛., 對不對,你也可以賣那個,, 你那家外賣外賣那個什麽,, 那個|solution你可以賣給他啊,, 你可以賣|,, 你也可以賣那個什麽佳潔跟大恒,, 因為因為|嘛., 好吧這這樣子哦,先講的是Intel,, lenovo,, 在這兩家,你們都可以加加進來,加完你們., 第二,因為哦,, 它,我希望它有sales,, 我先,它的sales它自己做Microsoft., 我是這樣子,這兩個是新單位,, 我覺得這樣的話你們就有margin,, 誰要需要resource就往這邊做,, 我再舉個,我再舉個例子|,, 假設他需要sourcing和technology,, 你也找他嘛., 技術在他手上,, 假設他printer沒有,那沒關係,我找|人家管,, 就他就外面,, printer的所有的跟sourcing好., 你就管他就好了嘛., 做完這邊那你就用它|,, 你報sourcing價錢多少,, 開始多少,未來的|,, 是|還是什麽,, 把它做好嘛,那你就有了嘛., 好所以你就這個,你就因為我一直在找說,, sales,sales團隊沒有RD沒辦法做生意的現在,, 不可能的., 你也不要自己養放在那邊,, 通通放在那邊,你你就你就是,你就是,, 你就||師,, 你|的||師., 好不好,所以我今天講到生意策略,, 我有講到組織策略哦,, 你是||師,, 那至於你的,, 你要賣你的,, 你的salary,, 你的你的薪資,, 你自己去定,, ...]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mts_df['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "** 下面都沒用 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** kmeans **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "X = np.array(list(df0['tfidf_vector'].values))\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "df0['kmeans_group'] = kmeans.predict(X)\n",
    "df0[['kmeans_group', 'doc']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# show groups\n",
    "df0['left_100'] = df0['doc'].map(lambda x: x[:100])\n",
    "df0.groupby(['kmeans_group', 'left_100']).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** --- Word2Vec Vectorize and KNN Classifier **\n",
    "** W2V **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X2= np.array(list(df0['w2v_vector_avg'].values))\n",
    "w2vkmeans = KMeans(n_clusters=4, random_state=0).fit(X2)\n",
    "df0['w2v_kmeans_group'] = w2vkmeans.predict(X2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** word2vec **\n",
    " - `size` is the dimensionality of the feature vectors.\n",
    " - `window` is the maximum distance between the current and predicted word within a sentence.\n",
    " - `min_count` = ignore all words with total frequency lower than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w2v_model = Word2Vec(lyrics_df['words'], min_count=1, size=10)\n",
    "#def words_to_w2v_avg(w2v, words):\n",
    "#    vecs = np.array([w2v[_] for _ in words if _ in w2v]) # get word's vector in word in w2v's vocabulary\n",
    "#    return vecs.mean(axis=0) # return average of vectors\n",
    "\n",
    "#lyrics_df['w2v_vector_avg'] = lyrics_df['words'].map(lambda x: words_to_w2v_avg(w2v, x))\n",
    "\n",
    "def keywords_to_w2v(w2v,keywords):\n",
    "    vecs = np.array([w2v[_] for _ in keywords if _ in w2v]) \n",
    "    return vecs\n",
    "\n",
    "lyrics_df['w2v_keywords'] = lyrics_df['keywords'].map(lambda x: keywords_to_w2v(w2v_model, x))\n",
    "\n",
    "vec=[]\n",
    "for i in lyrics_df['w2v_keywords']:\n",
    "    vec.extend(i)\n",
    "    \n",
    "vec = np.array(vec)\n",
    "tsne = TSNE(perplexity=10, n_components=2, init='pca', n_iter=5000)\n",
    "low_dim_embs = tsne.fit_transform(vec)\n",
    "\n",
    "tmpst=0\n",
    "tmpend=0\n",
    "low_tim_embs_list=[]\n",
    "for i in lyrics_df['w2v_keywords']:\n",
    "    tmpend = tmpst+ len(i)\n",
    "    low_tim_embs_list.append(low_dim_embs[tmpst:tmpend])\n",
    "    tmpst=tmpst+len(i)\n",
    "    \n",
    "lyrics_df['tsne_keywordsw2v'] = low_tim_embs_list\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(13,13))\n",
    "\n",
    "for row in range(lyrics_df.shape[0]):\n",
    "    keywords_w2v_vecs= lyrics_df['w2v_keywords'][row]\n",
    "    keywords=lyrics_df['keywords'][row]\n",
    "    plt.scatter(keywords_w2v_vecs[:, 0], keywords_w2v_vecs[:, 1])\n",
    "    for i, label in enumerate(keywords):\n",
    "        x, y = keywords_w2v_vecs[i][:2]\n",
    "        label = '{a}_{b}'.format(a=row,b=label)\n",
    "        plt.annotate(label, xy=(x, y), fontsize=10, ha='right', va='bottom')\n",
    "plt.title('Word2Vec')\n",
    "            \n",
    "plt.figure(figsize=(13,13))\n",
    "\n",
    "for row in range(lyrics_df.shape[0]):\n",
    "    keywords_w2v_vecs= lyrics_df['tsne_keywordsw2v'][row]\n",
    "    keywords=lyrics_df['keywords'][row]\n",
    "    plt.scatter(keywords_w2v_vecs[:, 0], keywords_w2v_vecs[:, 1])\n",
    "    for i, label in enumerate(keywords):\n",
    "        x, y = keywords_w2v_vecs[i][:2]\n",
    "        label = '{a}_{b}'.format(a=row,b=label)\n",
    "        plt.annotate(label, xy=(x, y), fontsize=12, ha='right', va='bottom')\n",
    "plt.title('Word2Vec + TSNE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
