{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import re\n",
    "import http.cookiejar\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from time import strftime\n",
    "import requests #HTTP for Humans \n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "loghandler = logging.handlers.TimedRotatingFileHandler(filename='logs/lyrics_crawler.log', when=\"midnight\")\n",
    "loghandler.setLevel(logging.INFO)\n",
    "fileformatter = logging.Formatter('%(asctime)s - %(filename)s [%(levelname)s] >>> %(message)s')\n",
    "loghandler.setFormatter(fileformatter)\n",
    "logger.addHandler(loghandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_folderexist(path='img/'):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "        except OSError as exc: \n",
    "            logger.exception(\"message\")\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "header = {\n",
    "'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "'Accept-Encoding':'gzip, deflate, br',\n",
    "'Accept-Language':'zh-TW,zh;q=0.8,en-US;q=0.6,en;q=0.4,zh-CN;q=0.2',\n",
    "'Cache-Control':'max-age=0',\n",
    "'Connection':'keep-alive',\n",
    "'Cookie':'PHPSESSID=ap27jqvh1enqk8nsvp9e01qau2; __atuvc=38%7C35; __atuvs=59a662f167ac5a52007',\n",
    "'DNT':'1',\n",
    "'Host':'mojim.com',\n",
    "'Referer':'https://mojim.com/twh100951.htm',\n",
    "'Upgrade-Insecure-Requests':'1',\n",
    "'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36', \n",
    "}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 取得歌手網頁 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mojim.com/twza1.htm 200 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://mojim.com/twza1.htm'\n",
    "sess = requests.Session()\n",
    "r = sess.get(url, headers = header)\n",
    "print(r.url, r.status_code, r.history)\n",
    "data = r.content\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "ul_data = soup.find(\"ul\", attrs={'class':['s_listA']})\n",
    "li_data = ul_data.find_all(\"li\")\n",
    "whoandhrefs = []\n",
    "for i in li_data:\n",
    "    a = i.find('a')\n",
    "    title=a.text\n",
    "    href = a['href']\n",
    "    whoandhrefs.append((title,href))\n",
    "\n",
    "whoandhrefs_df = pd.DataFrame(whoandhrefs, columns=['title','href'])\n",
    "whoandhrefs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_complete(folder):\n",
    "    try:\n",
    "        if 'complete.flag' in  os.listdir(folder):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def setcompleteflag(folder):\n",
    "    path = '{folder}{file}'.format(folder=folder, file='complete.flag')\n",
    "    file = open(path,'w') \n",
    "    file.write(str(dt.datetime.now()))\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "def crawler(folder, url):\n",
    "    sess = requests.Session()\n",
    "    r = sess.get(url, headers = header)\n",
    "    print( folder, r.url, r.status_code, r.history)\n",
    "    data = r.content\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    \n",
    "    dd_data = soup.find_all(\"dd\", attrs={'class':['hb2','hb3']})\n",
    "    all_tracks = []\n",
    "    for idx , part in enumerate(dd_data):\n",
    "        albuminfo = part.find_all('span', attrs={'class':'hc1'})[0]\n",
    "        if albuminfo.text in ['暫存']:\n",
    "            continue\n",
    "        album_str = albuminfo.find('a').contents[0]\n",
    "        yearinfo = part.find_all('span', attrs={'class':'hc2'})[0]\n",
    "        if len(yearinfo.contents)>2:\n",
    "            year_str= yearinfo.contents[2]\n",
    "        trackinfo = part.find_all('span', attrs={'class':['hc3','hc4']})\n",
    "        for tmp in trackinfo:\n",
    "            tracks = tmp.find_all('a')\n",
    "            for track in tracks: \n",
    "                name = track.contents[0]\n",
    "                link = track['href']\n",
    "                all_tracks.append((album_str, year_str, name, link))\n",
    "\n",
    "    all_tracks = pd.DataFrame(all_tracks)\n",
    "    \n",
    "    for idx, row in all_tracks.iterrows():\n",
    "        try:\n",
    "            htm = row[3]\n",
    "            filname='{y}_{n}'.format(y=row[1],n=row[2])\n",
    "            filname = filname.strip()\n",
    "            path = '{folder}{file}'.format(folder=folder, file=filname)\n",
    "            url = 'https://mojim.com{u}'.format(u=htm)\n",
    "            r = sess.get(url, headers = header)\n",
    "            lyrics_data = r.content\n",
    "            soup = BeautifulSoup(lyrics_data, \"html.parser\")\n",
    "\n",
    "            dl_data = soup.find_all(\"dl\", attrs={'class':'fsZx1'})\n",
    "            for idx , part in enumerate(dl_data):\n",
    "                dt_data = part.find_all('dt')\n",
    "                dd_data = part.find_all('dd')[0]\n",
    "                lyrics = dd_data.contents\n",
    "                lyrics = [w if isinstance(w,str) else '\\n' for w in lyrics]\n",
    "                lyric_str= ''.join(lyrics)\n",
    "                file = open(path,'w') \n",
    "                file.write(lyric_str) \n",
    "                file.close() \n",
    "        except Exception as e:\n",
    "            logger.exception(\"message\")\n",
    "            logger.error(\"error, {a},{b}\".format(a=idx,b=filname))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/六哲/ https://mojim.com/twh108782.htm 200 []\n",
      "text/鄭中基/ https://mojim.com/twh100168.htm 200 []\n",
      "text/齊秦/ https://mojim.com/twh100155.htm 200 []\n",
      "text/鹿晗/ https://mojim.com/twh135932.htm 200 []\n",
      "text/朴樹/ https://mojim.com/twh106229.htm 200 []\n",
      "text/TANK/ https://mojim.com/twh104824.htm 200 []\n",
      "text/張杰/ https://mojim.com/twh104500.htm 200 []\n",
      "text/曹格/ https://mojim.com/twh102360.htm 200 []\n",
      "text/陳柏宇/ https://mojim.com/twh105054.htm 200 []\n",
      "text/麥浚龍/ https://mojim.com/twh102248.htm 200 []\n",
      "text/陳百強/ https://mojim.com/twh100446.htm 200 []\n",
      "text/側田/ https://mojim.com/twh104790.htm 200 []\n",
      "text/陳曉東/ https://mojim.com/twh100119.htm 200 []\n",
      "text/蘇永康/ https://mojim.com/twh100184.htm 200 []\n",
      "text/吳宗憲/ https://mojim.com/twh100037.htm 200 []\n",
      "text/宋岳庭/ https://mojim.com/twh104300.htm 200 []\n",
      "text/陳昇/ https://mojim.com/twh100108.htm 200 []\n",
      "text/品冠/ https://mojim.com/twh101065.htm 200 []\n",
      "text/鄭伊健/ https://mojim.com/twh100169.htm 200 []\n",
      "text/謝霆鋒/ https://mojim.com/twh100180.htm 200 []\n"
     ]
    }
   ],
   "source": [
    "#sess = requests.Session()\n",
    "for idx, row in whoandhrefs_df.iterrows():\n",
    "    folder = 'text/lyrics/{who}/'.format(who=row['title'])\n",
    "    url = 'https://mojim.com{h}'.format(h=row['href'])\n",
    "    check_folderexist(folder)\n",
    "    if not check_complete(folder):\n",
    "        crawler(folder, url)\n",
    "        setcompleteflag(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** END ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "*** 以下備份抓一個歌手的流程 ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. 取得歌曲與網址列表**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mojim.com/twh100012.htm 200 []\n"
     ]
    }
   ],
   "source": [
    "#周杰倫\n",
    "#url = 'https://mojim.com/twh100951.htm'\n",
    "#folder = 'text/jaychou/'\n",
    "#陳奕迅\n",
    "#url = 'https://mojim.com/twh100111.htm'\n",
    "#folder ='text/easonchen/'\n",
    "#莫文蔚\n",
    "#url = 'https://mojim.com/twh100098.htm'\n",
    "#folder ='text/karenmok/'\n",
    "#八三夭\n",
    "#url = 'https://mojim.com/twh105532.htm'\n",
    "#folder ='text/831/'\n",
    "#五月天\n",
    "url = 'https://mojim.com/twh100012.htm'\n",
    "folder ='text/mayday/'\n",
    "\n",
    "\n",
    "\n",
    "sess = requests.Session()\n",
    "r = sess.get(url, headers = header)\n",
    "print(r.url, r.status_code, r.history)\n",
    "data = r.content\n",
    "soup = BeautifulSoup(data, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dd_data = soup.find_all(\"dd\", attrs={'class':['hb2','hb3']})\n",
    "all_tracks = []\n",
    "for idx , part in enumerate(dd_data):\n",
    "    albuminfo = part.find_all('span', attrs={'class':'hc1'})[0]\n",
    "    if albuminfo.text in ['暫存']:\n",
    "        continue\n",
    "    album_str = albuminfo.find('a').contents[0]\n",
    "    yearinfo = part.find_all('span', attrs={'class':'hc2'})[0]\n",
    "    if len(yearinfo.contents)>2:\n",
    "        year_str= yearinfo.contents[2]\n",
    "    trackinfo = part.find_all('span', attrs={'class':['hc3','hc4']})\n",
    "    for tmp in trackinfo:\n",
    "        tracks = tmp.find_all('a')\n",
    "        for track in tracks: \n",
    "            name = track.contents[0]\n",
    "            link = track['href']\n",
    "            all_tracks.append((album_str, year_str, name, link))\n",
    "        \n",
    "all_tracks = pd.DataFrame(all_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. 取得歌詞 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_もしも出会わなければ / 如果我們不曾相遇'\n",
      "error,  0 ,  2017-02_もしも出会わなければ / 如果我們不曾相遇\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_成功間近 / 成名在望'\n",
      "error,  0 ,  2017-02_成功間近 / 成名在望\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_兄弟 / 兄弟'\n",
      "error,  0 ,  2017-02_兄弟 / 兄弟\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_人生有限会社 / 人生有限公司'\n",
      "error,  0 ,  2017-02_人生有限会社 / 人生有限公司\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_あれから僕ら / 後來的我們'\n",
      "error,  0 ,  2017-02_あれから僕ら / 後來的我們\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_頑固 / 頑固'\n",
      "error,  0 ,  2017-02_頑固 / 頑固\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_Party Animal / 派對動物'\n",
      "error,  0 ,  2017-02_Party Animal / 派對動物\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_最高の一日 / 最好的一天'\n",
      "error,  0 ,  2017-02_最高の一日 / 最好的一天\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_少年漂流記 /少年他的奇幻漂流'\n",
      "error,  0 ,  2017-02_少年漂流記 /少年他的奇幻漂流\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_終わりの始まり / 終於結束的起點'\n",
      "error,  0 ,  2017-02_終わりの始まり / 終於結束的起點\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_どこでもドア / 任意門'\n",
      "error,  0 ,  2017-02_どこでもドア / 任意門\n",
      "[Errno 2] No such file or directory: 'text/mayday/2017-02_あっという間 / 轉眼'\n",
      "error,  0 ,  2017-02_あっという間 / 轉眼\n",
      "[Errno 2] No such file or directory: 'text/mayday/2015-06_青春の彼方/盛夏光年'\n",
      "error,  0 ,  2015-06_青春の彼方/盛夏光年\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_我(總統的書送的)'\n",
      "error,  0 ,  <br/>_我(總統的書送的)\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_王子麵'\n",
      "error,  0 ,  <br/>_王子麵\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_東海小王子'\n",
      "error,  0 ,  <br/>_東海小王子\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_虛弱'\n",
      "error,  0 ,  <br/>_虛弱\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_八月愛人'\n",
      "error,  0 ,  <br/>_八月愛人\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_金色大街'\n",
      "error,  0 ,  <br/>_金色大街\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_雌雄同體'\n",
      "error,  0 ,  <br/>_雌雄同體\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_從這裡開始(樂團國歌)'\n",
      "error,  0 ,  <br/>_從這裡開始(樂團國歌)\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_誰忘了愛我'\n",
      "error,  0 ,  <br/>_誰忘了愛我\n",
      "[Errno 2] No such file or directory: 'text/mayday/<br/>_I Can Fly'\n",
      "error,  0 ,  <br/>_I Can Fly\n"
     ]
    }
   ],
   "source": [
    "for idx, row in all_tracks.iterrows():\n",
    "    try:\n",
    "        htm = row[3]\n",
    "        filname='{y}_{n}'.format(y=row[1],n=row[2])\n",
    "        filname = filname.strip()\n",
    "        path = '{folder}{file}'.format(folder=folder, file=filname)\n",
    "        url = 'https://mojim.com{u}'.format(u=htm)\n",
    "        r = sess.get(url, headers = header)\n",
    "        lyrics_data = r.content\n",
    "        soup = BeautifulSoup(lyrics_data, \"html.parser\")\n",
    "\n",
    "        dl_data = soup.find_all(\"dl\", attrs={'class':'fsZx1'})\n",
    "        for idx , part in enumerate(dl_data):\n",
    "            dt_data = part.find_all('dt')\n",
    "            dd_data = part.find_all('dd')[0]\n",
    "            lyrics = dd_data.contents\n",
    "            lyrics = [w if isinstance(w,str) else '\\n' for w in lyrics]\n",
    "            lyric_str= ''.join(lyrics)\n",
    "            #all_lyrics.append(lyric_str)\n",
    "            file = open(path,'w') \n",
    "            file.write(lyric_str) \n",
    "            file.close() \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('error, ',idx,', ',filname)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
