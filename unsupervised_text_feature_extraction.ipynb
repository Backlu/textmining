{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Unuspervised Text Feature Extraction ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/jayhsu/work/github/textmining/dict.txt.big ...\n",
      "Loading model from cache /var/folders/yf/hq7ghg4j3ksb8k34wyh8vk2m0000gn/T/jieba.ub36e993abda9bbf53d1f5b38e3ae9b44.cache\n",
      "Loading model cost 2.340 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import html_template as ht\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "\n",
    "    \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "punct = u'''\\n +-％%:!),.:;?]}¢'\"、。〉》」』】〕〗〞︰|︱︳丨﹐､﹒﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠々‖•·ˇˉ―′’”([{£¥'\"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻︽︿﹁﹃﹙﹛﹝（｛“‘—_…~/#><'''\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(powerterm):\n",
    "    remove_list=[]\n",
    "    for tup in powerterm:\n",
    "        tmp2 = powerterm.copy()\n",
    "        tmp2.remove(tup)\n",
    "        tmp2 = dict(tmp2)\n",
    "        result = [(key, value) for key, value in tmp2.items() if tup[0] in key]\n",
    "        if len(result)==0:\n",
    "            continue\n",
    "        result = sorted(result, key=lambda tup: tup[1], reverse=True)\n",
    "        if tup[1] < result[0][1]:\n",
    "            remove_list.append(tup)\n",
    "\n",
    "    _ = list(map(lambda tup:powerterm.remove(tup), remove_list))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#計算分數的function\n",
    "def NC_Scoring(tmp, nature_chunk):\n",
    "    score =0\n",
    "    subscore_fb=subscore_fl=subscore_fr=subscore_fn=0\n",
    "    for chunk in nature_chunk:\n",
    "        if tmp == chunk:\n",
    "            subscore_fb = subscore_fb+1\n",
    "        if chunk.startswith(tmp):\n",
    "            subscore_fl = subscore_fl+1\n",
    "        if chunk.endswith(tmp):\n",
    "            subscore_fr = subscore_fr+1\n",
    "        if tmp in chunk:\n",
    "            subscore_fn = subscore_fn+1\n",
    "    score = 0.5*subscore_fb + 0.2*(subscore_fl+subscore_fr)+0.1*subscore_fn\n",
    "    score = len(tmp) * score\n",
    "    return float('%.3f'% score)\n",
    "\n",
    "#NC_Scoring('TITAN X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPowerTerm(powerterm, paragraph, nature_chunk):\n",
    "    #1. 斷字\n",
    "    corpora_sentence = []\n",
    "    for p in paragraph:\n",
    "        term_known = list(filter(lambda t: t[0] in p, powerterm))\n",
    "        term_known = list(map(lambda tup: tup[0], term_known))\n",
    "        for w in powerterm:\n",
    "            p = p.replace(w[0], '')\n",
    "        p_cut = list(p)\n",
    "        p_cut = list(filter(lambda x: x not in punct, p_cut))\n",
    "        corpora_sentence.append(p_cut+term_known)\n",
    "    \n",
    "    #2. LDA\n",
    "    sen_dictionary = gensim.corpora.Dictionary(corpora_sentence)  \n",
    "    sen_corpus = [sen_dictionary.doc2bow(text) for text in corpora_sentence]  \n",
    "\n",
    "    K = 5\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=sen_corpus, id2word=sen_dictionary, num_topics=K, update_every=0, passes=1)  \n",
    "    corpus_lda = lda[sen_corpus] \n",
    "    wordTopic = lda.print_topics(num_topics=-1, num_words=15)\n",
    "    wordTopic_pure = (list(map(lambda tup: (list(map(lambda tup: tup.split('*')[1].replace('\"','').strip(),tup[1].split('+')))   ),wordTopic)))\n",
    "\n",
    "    #3. 產生NxN term candidate, scoring排序, 取前5%為power term\n",
    "    wordTopic_NN = list(map(lambda x: list(map(lambda tup: tup[0]+tup[1], list(permutations(x, 2)))) , wordTopic_pure))\n",
    "    powerterm_candidate = set(sum(wordTopic_NN,[]))\n",
    "    powerterm = list(map(lambda term: (term, NC_Scoring(term, nature_chunk)), powerterm_candidate))\n",
    "    powerterm = list(filter(lambda tup: tup[1]>0,powerterm))\n",
    "    powerterm = sorted(powerterm, key=lambda tup: tup[1], reverse=True)\n",
    "    #powerterm = powerterm[: int(len(powerterm)*0.1)]\n",
    "    #powerterm = list(map(lambda tup: tup[0], powerterm))\n",
    "    return powerterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def power_term(doc, itera = 20):\n",
    "    #產生nature_chunk\n",
    "    paragraph = list(filter(lambda x: x != '...', doc.split('\\n')))\n",
    "    nature_chunk = []\n",
    "    for p in paragraph:\n",
    "        chunk = ''.join((char if char.isalpha() or char.isdigit() or char.isspace() else '|') for char in p).strip().split('|')\n",
    "        chunk = list(map(lambda x: x.strip(), chunk))\n",
    "        nature_chunk = nature_chunk+chunk\n",
    "    nature_chunk = list(filter(lambda a: a != '', nature_chunk))\n",
    "    \n",
    "    powerterm = []\n",
    "    powerterm_word=[]\n",
    "    for i in range(itera):\n",
    "        powerterm_new = getPowerTerm(powerterm, paragraph,nature_chunk)\n",
    "        powerterm_new = list(filter(lambda x: x[0] not in powerterm_word, powerterm_new))\n",
    "        powerterm = powerterm + powerterm_new\n",
    "        powerterm = sorted(powerterm, key=lambda tup: tup[1], reverse=True)\n",
    "        remove_duplicate(powerterm)\n",
    "        powerterm_word = list(map(lambda tup: tup[0], powerterm))\n",
    "    return powerterm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc = '【IT168 資訊】為了解決當今世界最尖端的技術挑戰之一，NVIDIA剛剛推出了全新的硬體和軟體，將前所未有地提高深度學習研究的速度、易用性和功用。\\n在人工智慧領域快速成長的深度學習技術是一項創新的計算引擎，可應用在從先進醫藥研究到全自動駕駛汽車的多元領域。\\n...\\nNVIDIA聯合創始人、總裁兼執行長黃仁勛先生在GPU技術大會的開幕主題演講活動上，對在座的四千名與會嘉賓展示三項將推動深度學習的新技術：\\n·NVIDIA GeForce GTX TITAN X - 為訓練深度神經網絡而開發的最強大的處理器。\\n·DIGITS深度學習GPU訓練系統 - 數據科學家與研究人員能利用這套軟體便捷地開發出高品質深度神經網絡。\\n·DIGITS DevBox - 全球最快的桌邊型深度學習工具 - 專為相關任務而打造，採用TITAN X GPU，搭配直觀易用的DIGITS訓練系統。\\nGeForce GTX TITAN X的另一面\\nTITANX是NVIDIA全新推出的旗艦級遊戲顯卡，但也特別適合用於深度學習。\\n...\\n在舊金山舉辦的遊戲開發者大會上讓各位先睹為快了TITAN X的身影，它以電影《霍比特人》里的史矛戈巨龍為藍本，播放了一段名為《暗影神偷》精彩的虛擬現實體驗。\\n...\\n在TITANX上能以4K的超高畫質呈現最新AAA遊戲大作的瑰麗畫面，可以在開啟FXAA高設定值的情況下，以每秒40幀(40FPS)運行《中土世界：暗影魔多》(Middle-earth:Shadow of Mordor)遊戲，而在九月發行的GeForce GTX 980上則是以30FPS來運行。\\n採用NVIDIA Maxwell GPU架構的TITAN X，結合3072個處理核心、單精度峰值性能為7 teraflops，加上板載的12GB顯存，在性能和性能功耗比方面皆是前代產品的兩倍。\\n憑藉強大的處理能力和336.5GB/s的帶寬，讓它能處理用於訓練深度神經網絡的數百萬的數據。例如，TITAN X在工業標準模型AlexNet上，花了不到三天的時間、使用120萬個ImageNet圖像數據集去訓練模型，而使角16核心的CPU得花上四十多天。\\n現已上市的GeForce GTX TITAN X售價為7999元人民幣。\\nDIGITS：通往最佳深度神經網絡的便捷之路\\n使用深度神經網絡來訓練電腦教自己如何分類和識別物體，是一件繁重又費時的事情。\\nDIGITS深度學習 GPU 訓練系統軟體自始至終都將為用戶提供所需數據，幫助用戶建立最優的深度神經網絡，改變上述的局面。\\n訪問http://developer.nvidia.com/diqits即可下載DIGITS深度學習GPU訓練系統，這是首套用於設計、訓練和驗證圖像分類深度神經網絡的多合一圖形系統。\\nDIGITS可在安裝、配置和訓練深度神經網絡過程中為用戶提供指導一處理複雜的工作好讓科學家能專心在研究活動和結果上。\\n得益於其直觀的用戶介面和強大的工作流程管理能力，不論是在本地系統還是在網絡上使用DIGITS，準備和加載訓練數據集都相當簡單。\\n這是同類系統中首個提供實時監控和可視化功能的系統，用戶可以對工作進行微調。它還支持GPU加速版本Caffe，目前，這一框架在眾多數據科學家和研究人員中都得到了廣泛使用，用於構建神經網絡。\\nDIGITS DevBox：全球最快的桌邊型深度學習機器\\nNVIDIA深度學習工程團隊為了自己的研發工作而開發的DIGITS DevBox，是一套集多項功能於一身的平台，能夠加快深度學習的研究活動。\\n...\\n它採用四個TITAN X GPU、從內存到I/O，DevBox的每個組件都進行了最佳化調試，可為最嚴苛的深度學習研究工作提供高效率的性能表現。\\n它己經預先安裝了數據科學家和研究人員在開發自己的深度神經網絡時，所需要使用到的各種軟體，包括DIGITS軟體包、最受歡迎的深度學習架構一Caffe、Theano和Torch，還有NVIDIA完整的GPU加速深度學習庫cuDNN 2.0。\\n所有這些都集結在這個高能效、靜默、運行流暢且外形優美的軟體包中，只需要普通的電源插座，低調安置在您的桌下即可。\\n較早期的多GPU訓練成果顯示，在關鍵深度學習測試中，DIGITS DevBox可以提供4倍於單個TITAN X的性能。使用DIGITS DevBox來訓練AlexNet只要13個小時就能完成，而使用最好的單GPU PC的話則是兩天，單純使用CPU系統的話則要一個月以上的時間。'   \n",
    "powerterm = power_term(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DIGITS', 21.6),\n",
       " ('NVIDIA', 9.0),\n",
       " ('DevBox', 8.4),\n",
       " ('深度神經網絡', 7.8),\n",
       " ('TITAN', 7.5),\n",
       " ('DIGITS深度學習', 7.0),\n",
       " ('DIGITS深度學習GPU', 5.2),\n",
       " ('使用DIGITS', 4.8),\n",
       " ('GeForce', 4.2),\n",
       " ('訓練系統', 4.0),\n",
       " ('運行', 3.2),\n",
       " ('NVIDIA深度學習', 3.0),\n",
       " ('U訓練系統', 3.0),\n",
       " ('DIGITS訓練系統', 3.0),\n",
       " ('的深度神經網絡', 2.8),\n",
       " ('遊戲', 2.6),\n",
       " ('數據', 2.6),\n",
       " ('數據科學家', 2.5),\n",
       " ('TITANX', 2.4),\n",
       " ('訓練深度神經網絡', 2.4),\n",
       " ('深度神經網絡的', 2.1),\n",
       " ('DevBox的', 2.1),\n",
       " ('NVIDIA剛', 2.1),\n",
       " ('DIGITS可', 2.1),\n",
       " ('採用TITAN', 2.1),\n",
       " ('軟體', 2.0),\n",
       " ('在TITAN', 1.8),\n",
       " ('的GeForce', 1.6),\n",
       " ('研究', 1.6),\n",
       " ('研究活動', 1.6),\n",
       " ('的深度學習', 1.5),\n",
       " ('GPU訓練', 1.5),\n",
       " ('是一', 1.4),\n",
       " ('用戶', 1.4),\n",
       " ('的DIGITS', 1.4),\n",
       " ('性能', 1.2),\n",
       " ('使用深度', 1.2),\n",
       " ('GTX', 1.2),\n",
       " ('技術', 1.2),\n",
       " ('個TITAN', 1.2),\n",
       " ('用於', 1.2),\n",
       " ('fe', 1.2),\n",
       " ('而使', 1.2),\n",
       " ('軟體包', 1.2),\n",
       " ('全球', 1.2),\n",
       " ('軟體包中', 1.2),\n",
       " ('習GPU訓練', 1.2),\n",
       " ('載DIGITS深度學習', 1.1),\n",
       " ('深度學習的', 1.0),\n",
       " ('開發', 1.0),\n",
       " ('可以', 1.0),\n",
       " ('深度學習研', 1.0),\n",
       " ('處理', 1.0),\n",
       " ('深度學習工', 1.0),\n",
       " ('工作', 1.0),\n",
       " ('le', 1.0),\n",
       " ('提供', 1.0),\n",
       " ('強大的處理', 1.0),\n",
       " ('的系統', 0.9),\n",
       " ('和軟體', 0.9),\n",
       " ('為訓練', 0.9),\n",
       " ('的數據', 0.9),\n",
       " ('處理器', 0.9),\n",
       " ('是一件', 0.9),\n",
       " ('研究人', 0.9),\n",
       " ('訓練深度神經網絡的', 0.9),\n",
       " ('ea', 0.8),\n",
       " ('di', 0.8),\n",
       " ('er', 0.8),\n",
       " ('為了', 0.8),\n",
       " ('DIGITS軟體', 0.8),\n",
       " ('佳深度神經網絡的', 0.8),\n",
       " ('深度神經網絡的便', 0.8),\n",
       " ('用戶提供', 0.8),\n",
       " ('PS', 0.8),\n",
       " ('40', 0.8),\n",
       " ('練深度神經網絡而', 0.8),\n",
       " ('用NVIDIA', 0.7),\n",
       " ('用深度神經網絡', 0.7),\n",
       " ('NVIDIA全', 0.7),\n",
       " ('是NVIDIA', 0.7),\n",
       " ('TITANX上', 0.7),\n",
       " ('深度學習的研究', 0.7),\n",
       " ('X的', 0.6),\n",
       " ('Ne', 0.6),\n",
       " ('et', 0.6),\n",
       " ('de', 0.6),\n",
       " ('在人', 0.6),\n",
       " ('動上', 0.6),\n",
       " ('的TITAN', 0.6),\n",
       " ('可為', 0.6),\n",
       " ('的多', 0.6),\n",
       " ('專為', 0.6),\n",
       " ('開發的', 0.6),\n",
       " ('的桌', 0.6),\n",
       " ('自己', 0.6),\n",
       " ('tp', 0.6),\n",
       " ('af', 0.6),\n",
       " ('而在', 0.6),\n",
       " ('了TITAN', 0.6),\n",
       " ('一面', 0.6),\n",
       " ('這一', 0.6),\n",
       " ('所有', 0.6),\n",
       " ('的工作', 0.6),\n",
       " ('而開發', 0.6),\n",
       " ('讓它', 0.6),\n",
       " ('速度', 0.6),\n",
       " ('自己的', 0.6),\n",
       " ('習研究', 0.6),\n",
       " ('和研究', 0.6),\n",
       " ('強大的處理能', 0.6),\n",
       " ('功用', 0.6),\n",
       " ('t上', 0.6),\n",
       " ('訓練系統軟體', 0.6),\n",
       " ('高深度學習', 0.5),\n",
       " ('動深度學習', 0.5),\n",
       " ('深度學習技', 0.5),\n",
       " ('快深度學習', 0.5),\n",
       " ('GPU技術', 0.5),\n",
       " ('的性', 0.4),\n",
       " ('的時', 0.4),\n",
       " ('id', 0.4),\n",
       " ('在開', 0.4),\n",
       " ('在GPU', 0.4),\n",
       " ('分類', 0.4),\n",
       " ('新的', 0.4),\n",
       " ('的GPU', 0.4),\n",
       " ('為用', 0.4),\n",
       " ('最快', 0.4),\n",
       " ('快的', 0.4),\n",
       " ('el', 0.4),\n",
       " ('op', 0.4),\n",
       " ('lo', 0.4),\n",
       " ('為7', 0.4),\n",
       " ('最佳', 0.4),\n",
       " ('FP', 0.4),\n",
       " ('0F', 0.4),\n",
       " ('的軟體包', 0.4),\n",
       " ('科學家能', 0.4),\n",
       " ('讓科學家', 0.4),\n",
       " ('研究工作', 0.4),\n",
       " ('工作提供', 0.4),\n",
       " ('大會', 0.4),\n",
       " ('技術是一', 0.4),\n",
       " ('功能', 0.4),\n",
       " ('網絡上', 0.3),\n",
       " ('在網絡', 0.3),\n",
       " ('系統的', 0.3),\n",
       " ('使用最', 0.3),\n",
       " ('的用戶', 0.3),\n",
       " ('的技術', 0.3),\n",
       " ('用於訓', 0.3),\n",
       " ('了數據', 0.3),\n",
       " ('練數據', 0.3),\n",
       " ('處理用', 0.3),\n",
       " ('合用於', 0.3),\n",
       " ('研究的', 0.3),\n",
       " ('用於深', 0.3),\n",
       " ('在研究', 0.3),\n",
       " ('能處理', 0.3),\n",
       " ('的遊戲', 0.3),\n",
       " ('遊戲大', 0.3),\n",
       " ('在開發', 0.3),\n",
       " ('遊戲顯', 0.3),\n",
       " ('是一項', 0.3),\n",
       " ('eN', 0.2),\n",
       " ('和T', 0.2),\n",
       " ('體和', 0.2),\n",
       " ('時的', 0.2),\n",
       " ('練A', 0.2),\n",
       " ('XA', 0.2),\n",
       " ('DN', 0.2),\n",
       " ('和訓', 0.2),\n",
       " ('的電', 0.2),\n",
       " ('能的', 0.2),\n",
       " ('練電', 0.2),\n",
       " ('練和', 0.2),\n",
       " ('用在', 0.2),\n",
       " ('To', 0.2),\n",
       " ('用的', 0.2),\n",
       " ('X在', 0.2),\n",
       " ('U系', 0.2),\n",
       " ('do', 0.2),\n",
       " ('te', 0.2),\n",
       " ('在這', 0.2),\n",
       " ('的最', 0.2),\n",
       " ('上的', 0.2),\n",
       " ('it', 0.2),\n",
       " ('以在', 0.2),\n",
       " ('的開', 0.2),\n",
       " ('2個', 0.2),\n",
       " ('會的', 0.2),\n",
       " ('能以', 0.2),\n",
       " ('的四', 0.2),\n",
       " ('在工', 0.2),\n",
       " ('的新', 0.2),\n",
       " ('會上', 0.2),\n",
       " ('0上', 0.2),\n",
       " ('能為', 0.2),\n",
       " ('類深', 0.2),\n",
       " ('上四', 0.2),\n",
       " ('能和', 0.2),\n",
       " ('和可', 0.2),\n",
       " ('以上', 0.2),\n",
       " ('上能', 0.2),\n",
       " ('高能', 0.2),\n",
       " ('可在', 0.2),\n",
       " ('新技', 0.2),\n",
       " ('行的', 0.2),\n",
       " ('和3', 0.2),\n",
       " ('的1', 0.2),\n",
       " ('為最', 0.2),\n",
       " ('出高', 0.2),\n",
       " ('作的', 0.2),\n",
       " ('用這', 0.2),\n",
       " ('是在', 0.2),\n",
       " ('為快', 0.2),\n",
       " ('中為', 0.2),\n",
       " ('13', 0.2),\n",
       " ('個高', 0.2),\n",
       " ('用1', 0.2),\n",
       " ('出的', 0.2),\n",
       " ('這個', 0.2),\n",
       " ('是以', 0.2),\n",
       " ('一個', 0.2),\n",
       " ('ve', 0.2),\n",
       " ('和加', 0.2),\n",
       " ('一圖', 0.2),\n",
       " ('A遊', 0.2),\n",
       " ('t圖', 0.2),\n",
       " ('pe', 0.2),\n",
       " ('於一', 0.2),\n",
       " ('工程', 0.2),\n",
       " ('的單', 0.2),\n",
       " ('單個', 0.2),\n",
       " ('在安', 0.2),\n",
       " ('79', 0.2),\n",
       " ('了一', 0.2),\n",
       " ('單G', 0.2),\n",
       " ('了最', 0.2),\n",
       " ('結在', 0.2),\n",
       " ('要使', 0.2),\n",
       " ('中都', 0.2),\n",
       " ('到的', 0.2),\n",
       " ('到全', 0.2),\n",
       " ('X是', 0.2),\n",
       " ('的速', 0.2),\n",
       " ('先安', 0.2),\n",
       " ('型A', 0.2),\n",
       " ('用C', 0.2),\n",
       " ('C的', 0.2),\n",
       " ('的C', 0.2),\n",
       " ('裝了', 0.2),\n",
       " ('它能', 0.2),\n",
       " ('載的', 0.2),\n",
       " ('一C', 0.2),\n",
       " ('元領', 0.2),\n",
       " ('件都', 0.2),\n",
       " ('rt', 0.2),\n",
       " ('新推', 0.2),\n",
       " ('9元', 0.2),\n",
       " ('Ma', 0.2),\n",
       " ('o和', 0.2),\n",
       " ('構的', 0.2),\n",
       " ('能功', 0.2),\n",
       " ('和功', 0.2),\n",
       " ('A高', 0.2),\n",
       " ('面和', 0.2),\n",
       " ('在本', 0.2),\n",
       " ('影神', 0.2),\n",
       " ('上使', 0.2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerterm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
